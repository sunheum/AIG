{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Decat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1번 구간 시작\n",
      "\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 1.0809 - accuracy: 0.5763 - val_loss: 1.0403 - val_accuracy: 0.7200\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9676 - accuracy: 0.6762 - val_loss: 0.8217 - val_accuracy: 0.6250\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8074 - accuracy: 0.6975 - val_loss: 0.7110 - val_accuracy: 0.7350\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7180 - accuracy: 0.7262 - val_loss: 0.6885 - val_accuracy: 0.7050\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6410 - accuracy: 0.7437 - val_loss: 0.5359 - val_accuracy: 0.7850\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5611 - accuracy: 0.7437 - val_loss: 0.4880 - val_accuracy: 0.7700\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4888 - accuracy: 0.7713 - val_loss: 0.4282 - val_accuracy: 0.7900\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4344 - accuracy: 0.7950 - val_loss: 0.4008 - val_accuracy: 0.7750\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4090 - accuracy: 0.7663 - val_loss: 0.3737 - val_accuracy: 0.8200\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3773 - accuracy: 0.8087 - val_loss: 0.3463 - val_accuracy: 0.7900\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3300 - accuracy: 0.8288 - val_loss: 0.2977 - val_accuracy: 0.8850\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.8675 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3247 - accuracy: 0.8475 - val_loss: 0.2846 - val_accuracy: 0.8750\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2549 - accuracy: 0.9000 - val_loss: 0.2205 - val_accuracy: 0.9450\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1779 - accuracy: 0.9438 - val_loss: 0.1726 - val_accuracy: 0.9400\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1224 - accuracy: 0.9600 - val_loss: 0.1309 - val_accuracy: 0.9500\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0953 - accuracy: 0.9750 - val_loss: 0.1028 - val_accuracy: 0.9550\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0613 - accuracy: 0.9837 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0418 - accuracy: 0.9950 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0338 - accuracy: 0.9962 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0267 - accuracy: 0.9987 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9987 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0193 - accuracy: 0.9987 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0158 - accuracy: 0.9987 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0121 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0115 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 9.9463e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 9.6156e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 9.2697e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.9159e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.5728e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.2627e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.9578e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.6689e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.4030e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.0899e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.8333e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.5977e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3774e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.1893e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 9.3272e-04 - accuracy: 1.0000 - val_loss: 6.0013e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 8.9522e-04 - accuracy: 1.0000 - val_loss: 5.7989e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 8.4948e-04 - accuracy: 1.0000 - val_loss: 5.6143e-04 - val_accuracy: 1.0000\n",
      "Epoch 00082: early stopping\n",
      "200/200 [==============================] - 0s 783us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   1번 구간 완료\n",
      "\n",
      "\n",
      "   2번 구간 시작\n",
      "\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 1.0455 - accuracy: 0.5600 - val_loss: 0.8939 - val_accuracy: 0.5300\n",
      "Epoch 2/200\n",
      "1600/1600 [==============================] - 2s 947us/step - loss: 0.7952 - accuracy: 0.6600 - val_loss: 0.6492 - val_accuracy: 0.7450\n",
      "Epoch 3/200\n",
      "1600/1600 [==============================] - 2s 975us/step - loss: 0.6552 - accuracy: 0.7206 - val_loss: 0.5695 - val_accuracy: 0.7850\n",
      "Epoch 4/200\n",
      "1600/1600 [==============================] - 2s 986us/step - loss: 0.5300 - accuracy: 0.7569 - val_loss: 0.4643 - val_accuracy: 0.7750\n",
      "Epoch 5/200\n",
      "1600/1600 [==============================] - 2s 989us/step - loss: 0.4543 - accuracy: 0.7675 - val_loss: 0.4083 - val_accuracy: 0.7925\n",
      "Epoch 6/200\n",
      "1600/1600 [==============================] - 2s 973us/step - loss: 0.3924 - accuracy: 0.7912 - val_loss: 0.3529 - val_accuracy: 0.8400\n",
      "Epoch 7/200\n",
      "1600/1600 [==============================] - 2s 955us/step - loss: 0.3352 - accuracy: 0.8269 - val_loss: 0.3243 - val_accuracy: 0.8575\n",
      "Epoch 8/200\n",
      "1600/1600 [==============================] - 2s 959us/step - loss: 0.3390 - accuracy: 0.8194 - val_loss: 0.3095 - val_accuracy: 0.8525\n",
      "Epoch 9/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2892 - accuracy: 0.8325 - val_loss: 0.2771 - val_accuracy: 0.8175\n",
      "Epoch 10/200\n",
      "1600/1600 [==============================] - 2s 963us/step - loss: 0.2488 - accuracy: 0.8525 - val_loss: 0.2223 - val_accuracy: 0.8850\n",
      "Epoch 11/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2149 - accuracy: 0.8806 - val_loss: 0.1776 - val_accuracy: 0.9150\n",
      "Epoch 12/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0883 - accuracy: 0.9712 - val_loss: 0.0353 - val_accuracy: 0.9975\n",
      "Epoch 13/200\n",
      "1600/1600 [==============================] - 2s 978us/step - loss: 0.0216 - accuracy: 0.9987 - val_loss: 0.0241 - val_accuracy: 0.9975\n",
      "Epoch 14/200\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 0.0115 - accuracy: 0.9994 - val_loss: 0.0211 - val_accuracy: 0.9975\n",
      "Epoch 15/200\n",
      "1600/1600 [==============================] - 2s 974us/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.0191 - val_accuracy: 0.9975\n",
      "Epoch 16/200\n",
      "1600/1600 [==============================] - 2s 981us/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.0187 - val_accuracy: 0.9975\n",
      "Epoch 17/200\n",
      "1600/1600 [==============================] - 2s 960us/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9975\n",
      "Epoch 18/200\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.0171 - val_accuracy: 0.9975\n",
      "Epoch 19/200\n",
      "1600/1600 [==============================] - 2s 971us/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0166 - val_accuracy: 0.9975\n",
      "Epoch 20/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0153 - val_accuracy: 0.9975\n",
      "Epoch 21/200\n",
      "1600/1600 [==============================] - 2s 994us/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0149 - val_accuracy: 0.9975\n",
      "Epoch 22/200\n",
      "1600/1600 [==============================] - 2s 978us/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0146 - val_accuracy: 0.9975\n",
      "Epoch 23/200\n",
      "1600/1600 [==============================] - 2s 993us/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 24/200\n",
      "1600/1600 [==============================] - 2s 965us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0135 - val_accuracy: 0.9975\n",
      "Epoch 25/200\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 26/200\n",
      "1600/1600 [==============================] - 2s 973us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9975\n",
      "Epoch 27/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9975\n",
      "Epoch 28/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9975\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 2s 971us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9975\n",
      "Epoch 30/200\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
      "Epoch 31/200\n",
      "1600/1600 [==============================] - 2s 956us/step - loss: 9.7206e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9975\n",
      "Epoch 32/200\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 8.8661e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9975\n",
      "Epoch 33/200\n",
      "1600/1600 [==============================] - 2s 966us/step - loss: 8.1514e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
      "Epoch 34/200\n",
      "1600/1600 [==============================] - 2s 981us/step - loss: 7.5019e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9975\n",
      "Epoch 35/200\n",
      "1600/1600 [==============================] - 2s 963us/step - loss: 7.0058e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9975\n",
      "Epoch 36/200\n",
      "1600/1600 [==============================] - 2s 968us/step - loss: 6.4938e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
      "Epoch 37/200\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 6.1411e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9975\n",
      "Epoch 38/200\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 5.7130e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9975\n",
      "Epoch 39/200\n",
      "1600/1600 [==============================] - 2s 990us/step - loss: 5.3632e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9975\n",
      "Epoch 40/200\n",
      "1600/1600 [==============================] - 2s 994us/step - loss: 5.0457e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9975\n",
      "Epoch 41/200\n",
      "1600/1600 [==============================] - 2s 997us/step - loss: 4.7811e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9975\n",
      "Epoch 42/200\n",
      "1600/1600 [==============================] - 2s 976us/step - loss: 4.5122e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9975\n",
      "Epoch 43/200\n",
      "1600/1600 [==============================] - 2s 962us/step - loss: 4.2771e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9975\n",
      "Epoch 44/200\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 4.0545e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9975\n",
      "Epoch 45/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 3.8546e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9975\n",
      "Epoch 46/200\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 3.7220e-04 - accuracy: 1.00 - 2s 990us/step - loss: 3.6744e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9975\n",
      "Epoch 47/200\n",
      "1600/1600 [==============================] - 2s 984us/step - loss: 3.4965e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9975\n",
      "Epoch 48/200\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 3.3383e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9975\n",
      "Epoch 49/200\n",
      "1600/1600 [==============================] - 2s 981us/step - loss: 3.1924e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9975\n",
      "Epoch 50/200\n",
      "1600/1600 [==============================] - 2s 980us/step - loss: 3.0663e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9975\n",
      "Epoch 51/200\n",
      "1600/1600 [==============================] - 2s 970us/step - loss: 2.9268e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9975\n",
      "Epoch 52/200\n",
      "1600/1600 [==============================] - 2s 968us/step - loss: 2.8072e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9975\n",
      "Epoch 53/200\n",
      "1600/1600 [==============================] - 2s 956us/step - loss: 2.6940e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9975\n",
      "Epoch 54/200\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 2.5879e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9975\n",
      "Epoch 55/200\n",
      "1600/1600 [==============================] - 2s 990us/step - loss: 2.4917e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9975\n",
      "Epoch 56/200\n",
      "1600/1600 [==============================] - 2s 987us/step - loss: 2.3974e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9975\n",
      "Epoch 57/200\n",
      "1600/1600 [==============================] - 2s 962us/step - loss: 2.3179e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9975\n",
      "Epoch 58/200\n",
      "1600/1600 [==============================] - 2s 953us/step - loss: 2.2275e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9975\n",
      "Epoch 59/200\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 2.1518e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9975\n",
      "Epoch 60/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 2.0742e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9975\n",
      "Epoch 61/200\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 2.0087e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9975\n",
      "Epoch 62/200\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 1.9426e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9975\n",
      "Epoch 63/200\n",
      "1600/1600 [==============================] - 2s 974us/step - loss: 1.8780e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9975\n",
      "Epoch 64/200\n",
      "1600/1600 [==============================] - 2s 982us/step - loss: 1.8175e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9975\n",
      "Epoch 65/200\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 1.7608e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9975\n",
      "Epoch 66/200\n",
      "1600/1600 [==============================] - 2s 979us/step - loss: 1.7078e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9975\n",
      "Epoch 67/200\n",
      "1600/1600 [==============================] - 2s 965us/step - loss: 1.6558e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9975\n",
      "Epoch 68/200\n",
      "1600/1600 [==============================] - 2s 967us/step - loss: 1.6065e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9975\n",
      "Epoch 69/200\n",
      "1600/1600 [==============================] - 2s 970us/step - loss: 1.5617e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9975\n",
      "Epoch 70/200\n",
      "1600/1600 [==============================] - 2s 984us/step - loss: 1.5138e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9975\n",
      "Epoch 71/200\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 1.4746e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9975\n",
      "Epoch 72/200\n",
      "1600/1600 [==============================] - 2s 962us/step - loss: 1.4415e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9975\n",
      "Epoch 73/200\n",
      "1600/1600 [==============================] - 2s 954us/step - loss: 1.3908e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9975\n",
      "Epoch 74/200\n",
      "1600/1600 [==============================] - 2s 972us/step - loss: 1.3525e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9975\n",
      "Epoch 75/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 1.3174e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9975\n",
      "Epoch 76/200\n",
      "1600/1600 [==============================] - 2s 994us/step - loss: 1.2810e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9975\n",
      "Epoch 77/200\n",
      "1600/1600 [==============================] - 2s 968us/step - loss: 1.2506e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9975\n",
      "Epoch 78/200\n",
      "1600/1600 [==============================] - 2s 979us/step - loss: 1.2168e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9975\n",
      "Epoch 79/200\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 1.1873e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9975\n",
      "Epoch 80/200\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 1.1584e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9975\n",
      "Epoch 81/200\n",
      "1600/1600 [==============================] - 2s 970us/step - loss: 1.1292e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9975\n",
      "Epoch 82/200\n",
      "1600/1600 [==============================] - 2s 986us/step - loss: 1.1012e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "1600/1600 [==============================] - 2s 988us/step - loss: 1.0758e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9975\n",
      "Epoch 84/200\n",
      "1600/1600 [==============================] - 2s 986us/step - loss: 1.0497e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9975\n",
      "Epoch 85/200\n",
      "1600/1600 [==============================] - 2s 953us/step - loss: 1.0260e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9975\n",
      "Epoch 86/200\n",
      "1600/1600 [==============================] - 2s 990us/step - loss: 1.0021e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9975\n",
      "Epoch 87/200\n",
      "1600/1600 [==============================] - 2s 971us/step - loss: 9.7916e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9975\n",
      "Epoch 88/200\n",
      "1600/1600 [==============================] - 2s 968us/step - loss: 9.5864e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9975\n",
      "Epoch 89/200\n",
      "1600/1600 [==============================] - 2s 990us/step - loss: 9.3697e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9975\n",
      "Epoch 90/200\n",
      "1600/1600 [==============================] - 2s 993us/step - loss: 9.1613e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9975\n",
      "Epoch 91/200\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 8.9588e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9975\n",
      "Epoch 92/200\n",
      "1600/1600 [==============================] - 2s 976us/step - loss: 8.7736e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9975\n",
      "Epoch 93/200\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 8.5832e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9975\n",
      "Epoch 94/200\n",
      "1600/1600 [==============================] - 2s 952us/step - loss: 8.4045e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 8.2345e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1600/1600 [==============================] - 2s 971us/step - loss: 8.0606e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 7.8969e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 7.7435e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1600/1600 [==============================] - 2s 979us/step - loss: 7.5890e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 7.4384e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 7.2917e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1600/1600 [==============================] - 2s 1000us/step - loss: 7.1541e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 7.0176e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1600/1600 [==============================] - 2s 974us/step - loss: 6.8828e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1600/1600 [==============================] - 2s 990us/step - loss: 6.7560e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 6.6334e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 6.5152e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 6.3778e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 6.2634e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1600/1600 [==============================] - 2s 950us/step - loss: 6.1553e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1600/1600 [==============================] - 2s 981us/step - loss: 6.0434e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1600/1600 [==============================] - 2s 981us/step - loss: 5.9375e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 5.8381e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 5.7265e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1600/1600 [==============================] - 2s 970us/step - loss: 5.6307e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 5.5331e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 00116: early stopping\n",
      "400/400 [==============================] - 0s 728us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   2번 구간 완료\n",
      "\n",
      "\n",
      "   3번 구간 시작\n",
      "\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.9859 - accuracy: 0.6271 - val_loss: 0.7435 - val_accuracy: 0.7567\n",
      "Epoch 2/200\n",
      "2400/2400 [==============================] - 2s 948us/step - loss: 0.6294 - accuracy: 0.7604 - val_loss: 0.5174 - val_accuracy: 0.7033\n",
      "Epoch 3/200\n",
      "2400/2400 [==============================] - 2s 957us/step - loss: 0.4388 - accuracy: 0.7871 - val_loss: 0.3998 - val_accuracy: 0.8233\n",
      "Epoch 4/200\n",
      "2400/2400 [==============================] - 2s 950us/step - loss: 0.3506 - accuracy: 0.8525 - val_loss: 0.2772 - val_accuracy: 0.8850\n",
      "Epoch 5/200\n",
      "2400/2400 [==============================] - 2s 961us/step - loss: 0.3008 - accuracy: 0.8833 - val_loss: 0.2537 - val_accuracy: 0.9200\n",
      "Epoch 6/200\n",
      "2400/2400 [==============================] - 2s 935us/step - loss: 0.1640 - accuracy: 0.9558 - val_loss: 0.1196 - val_accuracy: 0.9717\n",
      "Epoch 7/200\n",
      "2400/2400 [==============================] - 2s 929us/step - loss: 0.0606 - accuracy: 0.9862 - val_loss: 0.0517 - val_accuracy: 0.9883\n",
      "Epoch 8/200\n",
      "2400/2400 [==============================] - 2s 950us/step - loss: 0.0330 - accuracy: 0.9950 - val_loss: 0.0240 - val_accuracy: 0.9983\n",
      "Epoch 9/200\n",
      "2400/2400 [==============================] - 2s 938us/step - loss: 0.0198 - accuracy: 0.9983 - val_loss: 0.0206 - val_accuracy: 0.9983\n",
      "Epoch 10/200\n",
      "2400/2400 [==============================] - 2s 949us/step - loss: 0.0155 - accuracy: 0.9987 - val_loss: 0.0163 - val_accuracy: 0.9983\n",
      "Epoch 11/200\n",
      "2400/2400 [==============================] - 2s 957us/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.0141 - val_accuracy: 0.9983\n",
      "Epoch 12/200\n",
      "2400/2400 [==============================] - 2s 949us/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.0131 - val_accuracy: 0.9983\n",
      "Epoch 13/200\n",
      "2400/2400 [==============================] - 2s 946us/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.0118 - val_accuracy: 0.9983\n",
      "Epoch 14/200\n",
      "2400/2400 [==============================] - 2s 943us/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.0123 - val_accuracy: 0.9983\n",
      "Epoch 15/200\n",
      "2400/2400 [==============================] - 2s 963us/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 0.0102 - val_accuracy: 0.9983\n",
      "Epoch 16/200\n",
      "2400/2400 [==============================] - 2s 944us/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.0091 - val_accuracy: 0.9983\n",
      "Epoch 17/200\n",
      "2400/2400 [==============================] - 2s 924us/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0088 - val_accuracy: 0.9983\n",
      "Epoch 18/200\n",
      "2400/2400 [==============================] - 2s 944us/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
      "Epoch 19/200\n",
      "2400/2400 [==============================] - 2s 937us/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 2s 934us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 21/200\n",
      "2400/2400 [==============================] - 2s 962us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 22/200\n",
      "2400/2400 [==============================] - 2s 941us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 23/200\n",
      "2400/2400 [==============================] - 2s 949us/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
      "Epoch 24/200\n",
      "2400/2400 [==============================] - 2s 953us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
      "Epoch 25/200\n",
      "2400/2400 [==============================] - 2s 960us/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 26/200\n",
      "2400/2400 [==============================] - 2s 958us/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
      "Epoch 27/200\n",
      "2400/2400 [==============================] - 2s 939us/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
      "Epoch 28/200\n",
      "2400/2400 [==============================] - 2s 947us/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9983\n",
      "Epoch 29/200\n",
      "2400/2400 [==============================] - 2s 966us/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 0.9983\n",
      "Epoch 30/200\n",
      "2400/2400 [==============================] - 2s 952us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0037 - val_accuracy: 0.9983\n",
      "Epoch 31/200\n",
      "2400/2400 [==============================] - 2s 935us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9983\n",
      "Epoch 32/200\n",
      "2400/2400 [==============================] - 2s 944us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9983\n",
      "Epoch 33/200\n",
      "2400/2400 [==============================] - 2s 954us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "2400/2400 [==============================] - 2s 950us/step - loss: 8.5243e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "2400/2400 [==============================] - 2s 957us/step - loss: 7.0895e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "2400/2400 [==============================] - 2s 963us/step - loss: 6.0865e-04 - accuracy: 1.0000 - val_loss: 9.8448e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "2400/2400 [==============================] - 2s 933us/step - loss: 5.4690e-04 - accuracy: 1.0000 - val_loss: 9.3812e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "2400/2400 [==============================] - 2s 942us/step - loss: 4.6385e-04 - accuracy: 1.0000 - val_loss: 6.4470e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "2400/2400 [==============================] - 2s 926us/step - loss: 4.0633e-04 - accuracy: 1.0000 - val_loss: 6.3913e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "2400/2400 [==============================] - 2s 965us/step - loss: 3.6747e-04 - accuracy: 1.0000 - val_loss: 5.5777e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "2400/2400 [==============================] - 2s 932us/step - loss: 3.3671e-04 - accuracy: 1.0000 - val_loss: 4.9005e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "2400/2400 [==============================] - 2s 942us/step - loss: 3.1258e-04 - accuracy: 1.0000 - val_loss: 4.4765e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "2400/2400 [==============================] - 2s 937us/step - loss: 3.0402e-04 - accuracy: 1.0000 - val_loss: 4.1084e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "2400/2400 [==============================] - 2s 931us/step - loss: 2.7347e-04 - accuracy: 1.0000 - val_loss: 4.3274e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "2400/2400 [==============================] - 2s 966us/step - loss: 2.4857e-04 - accuracy: 1.0000 - val_loss: 3.5311e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "2400/2400 [==============================] - 2s 941us/step - loss: 2.3462e-04 - accuracy: 1.0000 - val_loss: 3.2624e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "2400/2400 [==============================] - 2s 924us/step - loss: 2.2127e-04 - accuracy: 1.0000 - val_loss: 3.0817e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "2400/2400 [==============================] - 2s 957us/step - loss: 2.0879e-04 - accuracy: 1.0000 - val_loss: 2.9022e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "2400/2400 [==============================] - 2s 939us/step - loss: 1.9902e-04 - accuracy: 1.0000 - val_loss: 2.8319e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "2400/2400 [==============================] - 2s 953us/step - loss: 1.8826e-04 - accuracy: 1.0000 - val_loss: 2.5529e-04 - val_accuracy: 1.0000\n",
      "Epoch 00050: early stopping\n",
      "600/600 [==============================] - 0s 723us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   3번 구간 완료\n",
      "\n",
      "\n",
      "   4번 구간 시작\n",
      "\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "3200/3200 [==============================] - 3s 1ms/step - loss: 0.9052 - accuracy: 0.6694 - val_loss: 0.6854 - val_accuracy: 0.7188\n",
      "Epoch 2/200\n",
      "3200/3200 [==============================] - 3s 925us/step - loss: 0.5309 - accuracy: 0.7631 - val_loss: 0.4278 - val_accuracy: 0.7862\n",
      "Epoch 3/200\n",
      "3200/3200 [==============================] - 3s 920us/step - loss: 0.3991 - accuracy: 0.7937 - val_loss: 0.3372 - val_accuracy: 0.8213\n",
      "Epoch 4/200\n",
      "3200/3200 [==============================] - 3s 930us/step - loss: 0.2566 - accuracy: 0.9013 - val_loss: 0.1758 - val_accuracy: 0.9350\n",
      "Epoch 5/200\n",
      "3200/3200 [==============================] - 3s 935us/step - loss: 0.1179 - accuracy: 0.9634 - val_loss: 0.0401 - val_accuracy: 0.9987\n",
      "Epoch 6/200\n",
      "3200/3200 [==============================] - 3s 930us/step - loss: 0.0340 - accuracy: 0.9972 - val_loss: 0.0200 - val_accuracy: 0.9987\n",
      "Epoch 7/200\n",
      "3200/3200 [==============================] - 3s 932us/step - loss: 0.0204 - accuracy: 0.9981 - val_loss: 0.0132 - val_accuracy: 0.9987\n",
      "Epoch 8/200\n",
      "3200/3200 [==============================] - 3s 935us/step - loss: 0.0209 - accuracy: 0.9972 - val_loss: 0.0152 - val_accuracy: 0.9987\n",
      "Epoch 9/200\n",
      "3200/3200 [==============================] - 3s 930us/step - loss: 0.0172 - accuracy: 0.9981 - val_loss: 0.0120 - val_accuracy: 0.9987\n",
      "Epoch 10/200\n",
      "3200/3200 [==============================] - 3s 945us/step - loss: 0.0143 - accuracy: 0.9981 - val_loss: 0.0092 - val_accuracy: 0.9987\n",
      "Epoch 11/200\n",
      "3200/3200 [==============================] - 3s 925us/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
      "Epoch 12/200\n",
      "3200/3200 [==============================] - 3s 919us/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 13/200\n",
      "3200/3200 [==============================] - 3s 936us/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 14/200\n",
      "3200/3200 [==============================] - 3s 940us/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 15/200\n",
      "3200/3200 [==============================] - 3s 945us/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
      "Epoch 16/200\n",
      "3200/3200 [==============================] - 3s 931us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "3200/3200 [==============================] - 3s 938us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "3200/3200 [==============================] - 3s 929us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "3200/3200 [==============================] - 3s 941us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.5625e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "3200/3200 [==============================] - 3s 940us/step - loss: 8.7047e-04 - accuracy: 1.0000 - val_loss: 7.8890e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "3200/3200 [==============================] - 3s 939us/step - loss: 7.2247e-04 - accuracy: 1.0000 - val_loss: 7.5647e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "3200/3200 [==============================] - 3s 927us/step - loss: 6.0665e-04 - accuracy: 1.0000 - val_loss: 5.9580e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 3s 927us/step - loss: 5.4117e-04 - accuracy: 1.0000 - val_loss: 5.3678e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "3200/3200 [==============================] - 3s 928us/step - loss: 4.7671e-04 - accuracy: 1.0000 - val_loss: 4.9400e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "3200/3200 [==============================] - 3s 937us/step - loss: 4.2880e-04 - accuracy: 1.0000 - val_loss: 4.4976e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "3200/3200 [==============================] - 3s 954us/step - loss: 3.8702e-04 - accuracy: 1.0000 - val_loss: 3.9130e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "3200/3200 [==============================] - 3s 949us/step - loss: 3.4685e-04 - accuracy: 1.0000 - val_loss: 3.5522e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "3200/3200 [==============================] - 3s 947us/step - loss: 3.1808e-04 - accuracy: 1.0000 - val_loss: 3.2322e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "3200/3200 [==============================] - 3s 965us/step - loss: 2.8972e-04 - accuracy: 1.0000 - val_loss: 3.0877e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "3200/3200 [==============================] - 3s 963us/step - loss: 2.6740e-04 - accuracy: 1.0000 - val_loss: 2.7660e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "3200/3200 [==============================] - 3s 930us/step - loss: 2.4816e-04 - accuracy: 1.0000 - val_loss: 2.5688e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "3200/3200 [==============================] - 3s 942us/step - loss: 2.3519e-04 - accuracy: 1.0000 - val_loss: 2.5416e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "3200/3200 [==============================] - 3s 950us/step - loss: 2.2097e-04 - accuracy: 1.0000 - val_loss: 2.3050e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "3200/3200 [==============================] - 3s 948us/step - loss: 2.0198e-04 - accuracy: 1.0000 - val_loss: 2.0645e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "3200/3200 [==============================] - 3s 922us/step - loss: 1.8576e-04 - accuracy: 1.0000 - val_loss: 1.9507e-04 - val_accuracy: 1.0000\n",
      "Epoch 00035: early stopping\n",
      "800/800 [==============================] - 1s 713us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   4번 구간 완료\n",
      "\n",
      "\n",
      "   5번 구간 시작\n",
      "\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.8978 - accuracy: 0.6008 - val_loss: 0.6484 - val_accuracy: 0.7660\n",
      "Epoch 2/200\n",
      "4000/4000 [==============================] - 4s 964us/step - loss: 0.4841 - accuracy: 0.7772 - val_loss: 0.3703 - val_accuracy: 0.8430\n",
      "Epoch 3/200\n",
      "4000/4000 [==============================] - 4s 958us/step - loss: 0.2816 - accuracy: 0.8808 - val_loss: 0.1771 - val_accuracy: 0.9440\n",
      "Epoch 4/200\n",
      "4000/4000 [==============================] - 4s 944us/step - loss: 0.0870 - accuracy: 0.9747 - val_loss: 0.0287 - val_accuracy: 0.9970\n",
      "Epoch 5/200\n",
      "4000/4000 [==============================] - 4s 954us/step - loss: 0.0232 - accuracy: 0.9975 - val_loss: 0.0183 - val_accuracy: 0.9980\n",
      "Epoch 6/200\n",
      "4000/4000 [==============================] - 4s 942us/step - loss: 0.0134 - accuracy: 0.9977 - val_loss: 0.0125 - val_accuracy: 0.9980\n",
      "Epoch 7/200\n",
      "4000/4000 [==============================] - 4s 956us/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 8/200\n",
      "4000/4000 [==============================] - 4s 969us/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 9/200\n",
      "4000/4000 [==============================] - 4s 941us/step - loss: 0.1225 - accuracy: 0.9640 - val_loss: 0.5914 - val_accuracy: 0.8800\n",
      "Epoch 10/200\n",
      "4000/4000 [==============================] - 4s 965us/step - loss: 0.1362 - accuracy: 0.9827 - val_loss: 0.0490 - val_accuracy: 0.9980\n",
      "Epoch 11/200\n",
      "4000/4000 [==============================] - 4s 942us/step - loss: 0.0337 - accuracy: 0.9973 - val_loss: 0.0236 - val_accuracy: 0.9980\n",
      "Epoch 12/200\n",
      "4000/4000 [==============================] - 4s 954us/step - loss: 0.0216 - accuracy: 0.9973 - val_loss: 0.0191 - val_accuracy: 0.9980\n",
      "Epoch 13/200\n",
      "4000/4000 [==============================] - 4s 942us/step - loss: 0.0189 - accuracy: 0.9973 - val_loss: 0.0175 - val_accuracy: 0.9980\n",
      "Epoch 00013: early stopping\n",
      "1000/1000 [==============================] - 1s 715us/step\n",
      "\n",
      " Test Accuracy: 0.9980\n",
      "   5번 구간 완료\n",
      "\n",
      "\n",
      "   6번 구간 시작\n",
      "\n",
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "4800/4800 [==============================] - 5s 995us/step - loss: 0.8522 - accuracy: 0.6342 - val_loss: 0.5696 - val_accuracy: 0.7483\n",
      "Epoch 2/200\n",
      "4800/4800 [==============================] - 5s 948us/step - loss: 0.4748 - accuracy: 0.7665 - val_loss: 0.3504 - val_accuracy: 0.7775\n",
      "Epoch 3/200\n",
      "4800/4800 [==============================] - 5s 957us/step - loss: 0.2993 - accuracy: 0.8417 - val_loss: 0.2103 - val_accuracy: 0.8842\n",
      "Epoch 4/200\n",
      "4800/4800 [==============================] - 5s 944us/step - loss: 0.0947 - accuracy: 0.9683 - val_loss: 0.0279 - val_accuracy: 0.9975\n",
      "Epoch 5/200\n",
      "4800/4800 [==============================] - 5s 959us/step - loss: 0.0229 - accuracy: 0.9975 - val_loss: 0.0136 - val_accuracy: 0.9983\n",
      "Epoch 6/200\n",
      "4800/4800 [==============================] - 5s 940us/step - loss: 0.0158 - accuracy: 0.9977 - val_loss: 0.0096 - val_accuracy: 0.9983\n",
      "Epoch 7/200\n",
      "4800/4800 [==============================] - 4s 937us/step - loss: 0.0444 - accuracy: 0.9948 - val_loss: 0.0403 - val_accuracy: 0.9983\n",
      "Epoch 8/200\n",
      "4800/4800 [==============================] - 5s 944us/step - loss: 0.0989 - accuracy: 0.9704 - val_loss: 0.0462 - val_accuracy: 0.9942\n",
      "Epoch 9/200\n",
      "4800/4800 [==============================] - 5s 940us/step - loss: 0.0303 - accuracy: 0.9958 - val_loss: 0.0148 - val_accuracy: 0.9983\n",
      "Epoch 10/200\n",
      "4800/4800 [==============================] - 5s 943us/step - loss: 0.0226 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9983\n",
      "Epoch 11/200\n",
      "4800/4800 [==============================] - 5s 956us/step - loss: 0.0215 - accuracy: 0.9967 - val_loss: 0.0127 - val_accuracy: 0.9983\n",
      "Epoch 00011: early stopping\n",
      "1200/1200 [==============================] - 1s 711us/step\n",
      "\n",
      " Test Accuracy: 0.9983\n",
      "   6번 구간 완료\n",
      "\n",
      "\n",
      "   7번 구간 시작\n",
      "\n",
      "Train on 5600 samples, validate on 1400 samples\n",
      "Epoch 1/200\n",
      "5600/5600 [==============================] - 6s 995us/step - loss: 0.7666 - accuracy: 0.6850 - val_loss: 0.4860 - val_accuracy: 0.7521\n",
      "Epoch 2/200\n",
      "5600/5600 [==============================] - 5s 946us/step - loss: 0.3574 - accuracy: 0.8325 - val_loss: 0.2360 - val_accuracy: 0.9107\n",
      "Epoch 3/200\n",
      "5600/5600 [==============================] - 5s 943us/step - loss: 0.1187 - accuracy: 0.9627 - val_loss: 0.0220 - val_accuracy: 0.9979\n",
      "Epoch 4/200\n",
      "5600/5600 [==============================] - 5s 933us/step - loss: 0.0188 - accuracy: 0.9977 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
      "Epoch 5/200\n",
      "5600/5600 [==============================] - 5s 951us/step - loss: 0.0129 - accuracy: 0.9975 - val_loss: 0.0077 - val_accuracy: 0.9986\n",
      "Epoch 6/200\n",
      "5600/5600 [==============================] - 5s 931us/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
      "Epoch 7/200\n",
      "5600/5600 [==============================] - 5s 938us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 0.9979\n",
      "Epoch 8/200\n",
      "5600/5600 [==============================] - 5s 948us/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0034 - val_accuracy: 0.9986\n",
      "Epoch 9/200\n",
      "5600/5600 [==============================] - 5s 936us/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "5600/5600 [==============================] - 5s 942us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "5600/5600 [==============================] - 5s 938us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "Epoch 12/200\n",
      "5600/5600 [==============================] - 5s 944us/step - loss: 0.0286 - accuracy: 0.9946 - val_loss: 5.6305 - val_accuracy: 0.4729\n",
      "Epoch 13/200\n",
      "5600/5600 [==============================] - 5s 933us/step - loss: 0.3518 - accuracy: 0.9400 - val_loss: 0.0310 - val_accuracy: 0.9964\n",
      "Epoch 14/200\n",
      "5600/5600 [==============================] - 5s 941us/step - loss: 0.0157 - accuracy: 0.9986 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 5s 935us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 00015: early stopping\n",
      "1400/1400 [==============================] - 1s 700us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   7번 구간 완료\n",
      "\n",
      "\n",
      "   8번 구간 시작\n",
      "\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 6s 970us/step - loss: 0.7136 - accuracy: 0.7180 - val_loss: 0.4103 - val_accuracy: 0.8062\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 6s 922us/step - loss: 0.2943 - accuracy: 0.8848 - val_loss: 0.2302 - val_accuracy: 0.9106\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 6s 937us/step - loss: 0.0602 - accuracy: 0.9878 - val_loss: 0.0230 - val_accuracy: 0.9981\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 6s 941us/step - loss: 0.0207 - accuracy: 0.9977 - val_loss: 0.0187 - val_accuracy: 0.9975\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 6s 931us/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0159 - val_accuracy: 0.9981\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 6s 941us/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.0130 - val_accuracy: 0.9981\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 6s 939us/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.0098 - val_accuracy: 0.9981\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 6s 923us/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 6s 936us/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 6s 941us/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 9.9841e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 6s 930us/step - loss: 8.7130e-04 - accuracy: 1.0000 - val_loss: 6.7319e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 6s 942us/step - loss: 6.0273e-04 - accuracy: 1.0000 - val_loss: 5.0675e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 6s 930us/step - loss: 4.5960e-04 - accuracy: 1.0000 - val_loss: 4.0360e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 6s 951us/step - loss: 3.6939e-04 - accuracy: 1.0000 - val_loss: 3.2998e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 6s 935us/step - loss: 3.0547e-04 - accuracy: 1.0000 - val_loss: 2.7751e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 6s 945us/step - loss: 2.5773e-04 - accuracy: 1.0000 - val_loss: 2.3785e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 6s 932us/step - loss: 2.2157e-04 - accuracy: 1.0000 - val_loss: 2.0912e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 6s 929us/step - loss: 1.9354e-04 - accuracy: 1.0000 - val_loss: 1.8096e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 6s 931us/step - loss: 1.6965e-04 - accuracy: 1.0000 - val_loss: 1.6031e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 6s 935us/step - loss: 1.5092e-04 - accuracy: 1.0000 - val_loss: 1.4283e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 6s 937us/step - loss: 1.3475e-04 - accuracy: 1.0000 - val_loss: 1.2848e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 6s 925us/step - loss: 1.2150e-04 - accuracy: 1.0000 - val_loss: 1.1614e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 6s 943us/step - loss: 1.0998e-04 - accuracy: 1.0000 - val_loss: 1.0574e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 6s 929us/step - loss: 1.0003e-04 - accuracy: 1.0000 - val_loss: 9.6585e-05 - val_accuracy: 1.0000\n",
      "Epoch 00024: early stopping\n",
      "1600/1600 [==============================] - 1s 697us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   8번 구간 완료\n",
      "\n",
      "\n",
      "   9번 구간 시작\n",
      "\n",
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/200\n",
      "7200/7200 [==============================] - 7s 978us/step - loss: 0.7212 - accuracy: 0.6915 - val_loss: 0.4370 - val_accuracy: 0.7867\n",
      "Epoch 2/200\n",
      "7200/7200 [==============================] - 7s 950us/step - loss: 0.2990 - accuracy: 0.8628 - val_loss: 0.1185 - val_accuracy: 0.9600\n",
      "Epoch 3/200\n",
      "7200/7200 [==============================] - 7s 952us/step - loss: 0.0319 - accuracy: 0.9956 - val_loss: 0.0159 - val_accuracy: 0.9978\n",
      "Epoch 4/200\n",
      "7200/7200 [==============================] - 7s 956us/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 5/200\n",
      "7200/7200 [==============================] - 7s 945us/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "7200/7200 [==============================] - 7s 956us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.5330e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "7200/7200 [==============================] - 7s 942us/step - loss: 7.4928e-04 - accuracy: 1.0000 - val_loss: 6.0362e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "7200/7200 [==============================] - 7s 950us/step - loss: 5.7496e-04 - accuracy: 1.0000 - val_loss: 4.6094e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "7200/7200 [==============================] - 7s 953us/step - loss: 4.1241e-04 - accuracy: 1.0000 - val_loss: 3.5603e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "7200/7200 [==============================] - 7s 940us/step - loss: 3.2736e-04 - accuracy: 1.0000 - val_loss: 2.8659e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "7200/7200 [==============================] - 7s 944us/step - loss: 2.7205e-04 - accuracy: 1.0000 - val_loss: 2.4101e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "7200/7200 [==============================] - 7s 942us/step - loss: 2.2376e-04 - accuracy: 1.0000 - val_loss: 2.0594e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "7200/7200 [==============================] - 7s 948us/step - loss: 1.9270e-04 - accuracy: 1.0000 - val_loss: 1.7790e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "7200/7200 [==============================] - 7s 948us/step - loss: 1.6405e-04 - accuracy: 1.0000 - val_loss: 1.5349e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "7200/7200 [==============================] - 7s 952us/step - loss: 1.5324e-04 - accuracy: 1.0000 - val_loss: 1.3580e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "7200/7200 [==============================] - 7s 940us/step - loss: 1.2728e-04 - accuracy: 1.0000 - val_loss: 1.1850e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "7200/7200 [==============================] - 7s 945us/step - loss: 1.1140e-04 - accuracy: 1.0000 - val_loss: 1.0526e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "7200/7200 [==============================] - 7s 951us/step - loss: 9.9333e-05 - accuracy: 1.0000 - val_loss: 9.4719e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "7200/7200 [==============================] - 7s 946us/step - loss: 8.9021e-05 - accuracy: 1.0000 - val_loss: 8.4687e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "7200/7200 [==============================] - 7s 958us/step - loss: 8.0708e-05 - accuracy: 1.0000 - val_loss: 7.6954e-05 - val_accuracy: 1.0000\n",
      "Epoch 00020: early stopping\n",
      "1800/1800 [==============================] - 1s 709us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   9번 구간 완료\n",
      "\n",
      "\n",
      "   10번 구간 시작\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "8000/8000 [==============================] - 8s 975us/step - loss: 0.6771 - accuracy: 0.7094 - val_loss: 0.3878 - val_accuracy: 0.8270\n",
      "Epoch 2/200\n",
      "8000/8000 [==============================] - 8s 954us/step - loss: 0.2492 - accuracy: 0.8840 - val_loss: 0.0274 - val_accuracy: 0.9985\n",
      "Epoch 3/200\n",
      "8000/8000 [==============================] - 8s 943us/step - loss: 0.0319 - accuracy: 0.9960 - val_loss: 0.0109 - val_accuracy: 0.9990\n",
      "Epoch 4/200\n",
      "8000/8000 [==============================] - 7s 936us/step - loss: 0.0213 - accuracy: 0.9969 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
      "Epoch 5/200\n",
      "8000/8000 [==============================] - 8s 942us/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 8s 941us/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "Epoch 7/200\n",
      "8000/8000 [==============================] - 7s 937us/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 8/200\n",
      "8000/8000 [==============================] - 8s 944us/step - loss: 8.6003e-04 - accuracy: 1.0000 - val_loss: 5.9205e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "8000/8000 [==============================] - 8s 939us/step - loss: 4.8881e-04 - accuracy: 1.0000 - val_loss: 4.4596e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "8000/8000 [==============================] - 8s 953us/step - loss: 3.6615e-04 - accuracy: 1.0000 - val_loss: 3.5000e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "8000/8000 [==============================] - 8s 943us/step - loss: 2.8941e-04 - accuracy: 1.0000 - val_loss: 2.8588e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "8000/8000 [==============================] - 8s 943us/step - loss: 2.3527e-04 - accuracy: 1.0000 - val_loss: 2.3867e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "8000/8000 [==============================] - 8s 938us/step - loss: 1.9597e-04 - accuracy: 1.0000 - val_loss: 2.0251e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "8000/8000 [==============================] - 8s 955us/step - loss: 1.6634e-04 - accuracy: 1.0000 - val_loss: 1.7497e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "8000/8000 [==============================] - 8s 948us/step - loss: 1.4304e-04 - accuracy: 1.0000 - val_loss: 1.5275e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "8000/8000 [==============================] - 8s 940us/step - loss: 1.2427e-04 - accuracy: 1.0000 - val_loss: 1.3454e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "8000/8000 [==============================] - 8s 949us/step - loss: 1.0923e-04 - accuracy: 1.0000 - val_loss: 1.1943e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "8000/8000 [==============================] - 8s 945us/step - loss: 9.6879e-05 - accuracy: 1.0000 - val_loss: 1.0748e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "8000/8000 [==============================] - 8s 939us/step - loss: 8.6467e-05 - accuracy: 1.0000 - val_loss: 9.6866e-05 - val_accuracy: 1.0000\n",
      "Epoch 00019: early stopping\n",
      "2000/2000 [==============================] - 1s 690us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   10번 구간 완료\n",
      "\n",
      "\n",
      "   11번 구간 시작\n",
      "\n",
      "Train on 8800 samples, validate on 2200 samples\n",
      "Epoch 1/200\n",
      "8800/8800 [==============================] - 9s 972us/step - loss: 0.6388 - accuracy: 0.7325 - val_loss: 0.3515 - val_accuracy: 0.8177\n",
      "Epoch 2/200\n",
      "8800/8800 [==============================] - 8s 961us/step - loss: 0.1878 - accuracy: 0.9160 - val_loss: 0.0419 - val_accuracy: 0.9936\n",
      "Epoch 3/200\n",
      "8800/8800 [==============================] - 8s 947us/step - loss: 0.0324 - accuracy: 0.9966 - val_loss: 0.0242 - val_accuracy: 0.9968\n",
      "Epoch 4/200\n",
      "8800/8800 [==============================] - 8s 932us/step - loss: 0.0197 - accuracy: 0.9975 - val_loss: 0.0207 - val_accuracy: 0.9968\n",
      "Epoch 5/200\n",
      "8800/8800 [==============================] - 8s 941us/step - loss: 0.0170 - accuracy: 0.9975 - val_loss: 0.0180 - val_accuracy: 0.9973\n",
      "Epoch 6/200\n",
      "8800/8800 [==============================] - 8s 947us/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0130 - val_accuracy: 0.9968\n",
      "Epoch 7/200\n",
      "8800/8800 [==============================] - 8s 949us/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0111 - val_accuracy: 0.9968\n",
      "Epoch 8/200\n",
      "8800/8800 [==============================] - 8s 949us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
      "Epoch 9/200\n",
      "8800/8800 [==============================] - 8s 938us/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.0049 - val_accuracy: 0.9977\n",
      "Epoch 10/200\n",
      "8800/8800 [==============================] - 8s 939us/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "8800/8800 [==============================] - 8s 950us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.1063e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "8800/8800 [==============================] - 8s 944us/step - loss: 6.0032e-04 - accuracy: 1.0000 - val_loss: 6.0583e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "8800/8800 [==============================] - 8s 931us/step - loss: 4.0403e-04 - accuracy: 1.0000 - val_loss: 4.4074e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "8800/8800 [==============================] - 8s 940us/step - loss: 2.9921e-04 - accuracy: 1.0000 - val_loss: 3.6865e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "8800/8800 [==============================] - 8s 939us/step - loss: 2.4461e-04 - accuracy: 1.0000 - val_loss: 2.9548e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "8800/8800 [==============================] - 8s 946us/step - loss: 1.9572e-04 - accuracy: 1.0000 - val_loss: 2.5053e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "8800/8800 [==============================] - 8s 946us/step - loss: 1.6845e-04 - accuracy: 1.0000 - val_loss: 2.0952e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "8800/8800 [==============================] - 8s 943us/step - loss: 1.4250e-04 - accuracy: 1.0000 - val_loss: 1.8741e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "8800/8800 [==============================] - 8s 944us/step - loss: 1.2446e-04 - accuracy: 1.0000 - val_loss: 1.7689e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "8800/8800 [==============================] - 8s 932us/step - loss: 1.0981e-04 - accuracy: 1.0000 - val_loss: 1.4716e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "8800/8800 [==============================] - 8s 944us/step - loss: 9.7904e-05 - accuracy: 1.0000 - val_loss: 1.3238e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "8800/8800 [==============================] - 8s 939us/step - loss: 8.6852e-05 - accuracy: 1.0000 - val_loss: 1.2364e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "8800/8800 [==============================] - 8s 950us/step - loss: 7.7978e-05 - accuracy: 1.0000 - val_loss: 1.2177e-04 - val_accuracy: 1.0000\n",
      "Epoch 00023: early stopping\n",
      "2200/2200 [==============================] - 2s 698us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   11번 구간 완료\n",
      "\n",
      "\n",
      "   12번 구간 시작\n",
      "\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/200\n",
      "9600/9600 [==============================] - 9s 963us/step - loss: 0.5921 - accuracy: 0.7505 - val_loss: 0.3272 - val_accuracy: 0.8617\n",
      "Epoch 2/200\n",
      "9600/9600 [==============================] - 9s 944us/step - loss: 0.1148 - accuracy: 0.9649 - val_loss: 0.0144 - val_accuracy: 0.9987\n",
      "Epoch 3/200\n",
      "9600/9600 [==============================] - 9s 957us/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
      "Epoch 4/200\n",
      "9600/9600 [==============================] - 9s 936us/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
      "Epoch 5/200\n",
      "9600/9600 [==============================] - 9s 943us/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 6/200\n",
      "9600/9600 [==============================] - 9s 952us/step - loss: 0.0477 - accuracy: 0.9899 - val_loss: 0.0210 - val_accuracy: 0.9987\n",
      "Epoch 7/200\n",
      "9600/9600 [==============================] - 9s 944us/step - loss: 0.0242 - accuracy: 0.9967 - val_loss: 0.0106 - val_accuracy: 0.9987\n",
      "Epoch 8/200\n",
      "9600/9600 [==============================] - 9s 946us/step - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
      "Epoch 9/200\n",
      "9600/9600 [==============================] - 9s 957us/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
      "Epoch 10/200\n",
      "9600/9600 [==============================] - 9s 944us/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 00010: early stopping\n",
      "2400/2400 [==============================] - 2s 717us/step\n",
      "\n",
      " Test Accuracy: 0.9987\n",
      "   12번 구간 완료\n",
      "\n",
      "\n",
      "   13번 구간 시작\n",
      "\n",
      "Train on 10400 samples, validate on 2600 samples\n",
      "Epoch 1/200\n",
      "10400/10400 [==============================] - 10s 969us/step - loss: 0.5989 - accuracy: 0.7546 - val_loss: 0.3083 - val_accuracy: 0.8592\n",
      "Epoch 2/200\n",
      "10400/10400 [==============================] - 10s 944us/step - loss: 0.0907 - accuracy: 0.9733 - val_loss: 0.0255 - val_accuracy: 0.9958\n",
      "Epoch 3/200\n",
      "10400/10400 [==============================] - 10s 948us/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.0136 - val_accuracy: 0.9965\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400/10400 [==============================] - 10s 943us/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0095 - val_accuracy: 0.9965\n",
      "Epoch 5/200\n",
      "10400/10400 [==============================] - 10s 948us/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.0057 - val_accuracy: 0.9965\n",
      "Epoch 6/200\n",
      "10400/10400 [==============================] - 10s 943us/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "10400/10400 [==============================] - 10s 948us/step - loss: 0.0297 - accuracy: 0.9962 - val_loss: 0.0249 - val_accuracy: 0.9965\n",
      "Epoch 8/200\n",
      "10400/10400 [==============================] - 10s 953us/step - loss: 0.0169 - accuracy: 0.9974 - val_loss: 0.0193 - val_accuracy: 0.9965\n",
      "Epoch 9/200\n",
      "10400/10400 [==============================] - 10s 950us/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.0167 - val_accuracy: 0.9965\n",
      "Epoch 10/200\n",
      "10400/10400 [==============================] - 10s 951us/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "10400/10400 [==============================] - 10s 946us/step - loss: 6.1366e-04 - accuracy: 1.0000 - val_loss: 7.3884e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "10400/10400 [==============================] - 10s 948us/step - loss: 4.0809e-04 - accuracy: 1.0000 - val_loss: 5.7166e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "10400/10400 [==============================] - 10s 946us/step - loss: 3.1259e-04 - accuracy: 1.0000 - val_loss: 4.5431e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "10400/10400 [==============================] - 10s 930us/step - loss: 2.5009e-04 - accuracy: 1.0000 - val_loss: 3.6586e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "10400/10400 [==============================] - 10s 928us/step - loss: 2.0491e-04 - accuracy: 1.0000 - val_loss: 3.0937e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "10400/10400 [==============================] - 10s 956us/step - loss: 1.7175e-04 - accuracy: 1.0000 - val_loss: 2.7503e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "10400/10400 [==============================] - 10s 949us/step - loss: 1.4609e-04 - accuracy: 1.0000 - val_loss: 2.3537e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "10400/10400 [==============================] - 10s 957us/step - loss: 1.2596e-04 - accuracy: 1.0000 - val_loss: 2.1076e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "10400/10400 [==============================] - 10s 945us/step - loss: 1.1007e-04 - accuracy: 1.0000 - val_loss: 1.8739e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "10400/10400 [==============================] - 10s 948us/step - loss: 9.6974e-05 - accuracy: 1.0000 - val_loss: 1.7176e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "10400/10400 [==============================] - 10s 926us/step - loss: 8.6196e-05 - accuracy: 1.0000 - val_loss: 1.5491e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "10400/10400 [==============================] - 10s 947us/step - loss: 7.6990e-05 - accuracy: 1.0000 - val_loss: 1.4177e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "10400/10400 [==============================] - 10s 949us/step - loss: 6.9121e-05 - accuracy: 1.0000 - val_loss: 1.3268e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "10400/10400 [==============================] - 10s 947us/step - loss: 6.2571e-05 - accuracy: 1.0000 - val_loss: 1.2380e-04 - val_accuracy: 1.0000\n",
      "Epoch 00024: early stopping\n",
      "2600/2600 [==============================] - 2s 726us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   13번 구간 완료\n",
      "\n",
      "\n",
      "   14번 구간 시작\n",
      "\n",
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/200\n",
      "11200/11200 [==============================] - 11s 965us/step - loss: 0.5686 - accuracy: 0.7679 - val_loss: 0.2308 - val_accuracy: 0.9107\n",
      "Epoch 2/200\n",
      "11200/11200 [==============================] - 11s 945us/step - loss: 0.0589 - accuracy: 0.9836 - val_loss: 0.0231 - val_accuracy: 0.9968\n",
      "Epoch 3/200\n",
      "11200/11200 [==============================] - 11s 950us/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0207 - val_accuracy: 0.9968\n",
      "Epoch 4/200\n",
      "11200/11200 [==============================] - 11s 952us/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0083 - val_accuracy: 0.9971\n",
      "Epoch 5/200\n",
      "11200/11200 [==============================] - 11s 942us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "11200/11200 [==============================] - 11s 953us/step - loss: 7.6279e-04 - accuracy: 1.0000 - val_loss: 6.0042e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "11200/11200 [==============================] - 11s 948us/step - loss: 3.7524e-04 - accuracy: 1.0000 - val_loss: 3.9128e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "11200/11200 [==============================] - 10s 928us/step - loss: 2.6358e-04 - accuracy: 1.0000 - val_loss: 2.7548e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "11200/11200 [==============================] - 11s 944us/step - loss: 1.9688e-04 - accuracy: 1.0000 - val_loss: 2.1281e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "11200/11200 [==============================] - 10s 936us/step - loss: 1.5414e-04 - accuracy: 1.0000 - val_loss: 1.7166e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "11200/11200 [==============================] - 11s 941us/step - loss: 0.2537 - accuracy: 0.9522 - val_loss: 0.0974 - val_accuracy: 0.9939\n",
      "Epoch 12/200\n",
      "11200/11200 [==============================] - 11s 948us/step - loss: 0.0339 - accuracy: 0.9966 - val_loss: 0.0377 - val_accuracy: 0.9939\n",
      "Epoch 13/200\n",
      "11200/11200 [==============================] - 10s 936us/step - loss: 0.0225 - accuracy: 0.9966 - val_loss: 0.0354 - val_accuracy: 0.9943\n",
      "Epoch 14/200\n",
      "11200/11200 [==============================] - 11s 945us/step - loss: 0.0193 - accuracy: 0.9974 - val_loss: 0.0214 - val_accuracy: 0.9968\n",
      "Epoch 15/200\n",
      "11200/11200 [==============================] - 11s 964us/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 0.0203 - val_accuracy: 0.9968\n",
      "Epoch 00015: early stopping\n",
      "2800/2800 [==============================] - 2s 752us/step\n",
      "\n",
      " Test Accuracy: 0.9968\n",
      "   14번 구간 완료\n",
      "\n",
      "\n",
      "   15번 구간 시작\n",
      "\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 12s 960us/step - loss: 0.5341 - accuracy: 0.7860 - val_loss: 0.1307 - val_accuracy: 0.9583\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 11s 943us/step - loss: 0.0401 - accuracy: 0.9916 - val_loss: 0.0117 - val_accuracy: 0.9980\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 11s 943us/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 11s 940us/step - loss: 0.0750 - accuracy: 0.9910 - val_loss: 0.0203 - val_accuracy: 0.9980\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 11s 940us/step - loss: 0.0194 - accuracy: 0.9973 - val_loss: 0.0146 - val_accuracy: 0.9980\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 11s 938us/step - loss: 0.0166 - accuracy: 0.9973 - val_loss: 0.0130 - val_accuracy: 0.9980\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 11s 949us/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 0.0121 - val_accuracy: 0.9980\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 11s 935us/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
      "Epoch 00008: early stopping\n",
      "3000/3000 [==============================] - 2s 718us/step\n",
      "\n",
      " Test Accuracy: 0.9983\n",
      "   15번 구간 완료\n",
      "\n",
      "\n",
      "   16번 구간 시작\n",
      "\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/200\n",
      "12800/12800 [==============================] - 12s 955us/step - loss: 0.5276 - accuracy: 0.7852 - val_loss: 0.1494 - val_accuracy: 0.9506\n",
      "Epoch 2/200\n",
      "12800/12800 [==============================] - 12s 938us/step - loss: 0.0435 - accuracy: 0.9905 - val_loss: 0.0159 - val_accuracy: 0.9978\n",
      "Epoch 3/200\n",
      "12800/12800 [==============================] - 12s 943us/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 4/200\n",
      "12800/12800 [==============================] - 12s 938us/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0078 - val_accuracy: 0.9978\n",
      "Epoch 5/200\n",
      "12800/12800 [==============================] - 12s 930us/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0200 - val_accuracy: 0.9972\n",
      "Epoch 6/200\n",
      "12800/12800 [==============================] - 12s 927us/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0071 - val_accuracy: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "12800/12800 [==============================] - 12s 932us/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 7.0894e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "12800/12800 [==============================] - 12s 939us/step - loss: 4.7784e-04 - accuracy: 1.0000 - val_loss: 3.9438e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 3.0051e-04 - accuracy: 1.0000 - val_loss: 2.7186e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "12800/12800 [==============================] - 12s 939us/step - loss: 2.1532e-04 - accuracy: 1.0000 - val_loss: 2.0313e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "12800/12800 [==============================] - 12s 933us/step - loss: 1.6574e-04 - accuracy: 1.0000 - val_loss: 1.5942e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "12800/12800 [==============================] - 12s 939us/step - loss: 1.3230e-04 - accuracy: 1.0000 - val_loss: 1.3020e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "12800/12800 [==============================] - 12s 934us/step - loss: 1.0924e-04 - accuracy: 1.0000 - val_loss: 1.0894e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "12800/12800 [==============================] - 12s 939us/step - loss: 9.1471e-05 - accuracy: 1.0000 - val_loss: 9.2292e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "12800/12800 [==============================] - 12s 938us/step - loss: 7.8059e-05 - accuracy: 1.0000 - val_loss: 7.9426e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "12800/12800 [==============================] - 12s 954us/step - loss: 6.7462e-05 - accuracy: 1.0000 - val_loss: 6.9681e-05 - val_accuracy: 1.0000\n",
      "Epoch 00016: early stopping\n",
      "3200/3200 [==============================] - 2s 704us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   16번 구간 완료\n",
      "\n",
      "\n",
      "   17번 구간 시작\n",
      "\n",
      "Train on 13600 samples, validate on 3400 samples\n",
      "Epoch 1/200\n",
      "13600/13600 [==============================] - 13s 969us/step - loss: 0.5358 - accuracy: 0.7650 - val_loss: 0.2499 - val_accuracy: 0.8635\n",
      "Epoch 2/200\n",
      "13600/13600 [==============================] - 13s 937us/step - loss: 0.0542 - accuracy: 0.9837 - val_loss: 0.0243 - val_accuracy: 0.9974\n",
      "Epoch 3/200\n",
      "13600/13600 [==============================] - 13s 934us/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 0.0125 - val_accuracy: 0.9974\n",
      "Epoch 4/200\n",
      "13600/13600 [==============================] - 13s 940us/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 7.4328e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "13600/13600 [==============================] - 13s 939us/step - loss: 6.3584e-04 - accuracy: 1.0000 - val_loss: 4.5479e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "13600/13600 [==============================] - 13s 940us/step - loss: 4.0447e-04 - accuracy: 1.0000 - val_loss: 3.1570e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "13600/13600 [==============================] - 13s 945us/step - loss: 2.9195e-04 - accuracy: 1.0000 - val_loss: 2.6157e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "13600/13600 [==============================] - 13s 943us/step - loss: 3.1510e-04 - accuracy: 1.0000 - val_loss: 1.9248e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "13600/13600 [==============================] - 13s 945us/step - loss: 1.6983e-04 - accuracy: 1.0000 - val_loss: 1.4606e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "13600/13600 [==============================] - 13s 941us/step - loss: 1.3406e-04 - accuracy: 1.0000 - val_loss: 1.1691e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "13600/13600 [==============================] - 13s 942us/step - loss: 1.0955e-04 - accuracy: 1.0000 - val_loss: 9.6243e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "13600/13600 [==============================] - 13s 936us/step - loss: 9.1583e-05 - accuracy: 1.0000 - val_loss: 8.1113e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "13600/13600 [==============================] - 13s 935us/step - loss: 7.7456e-05 - accuracy: 1.0000 - val_loss: 6.9521e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "13600/13600 [==============================] - 13s 941us/step - loss: 6.6516e-05 - accuracy: 1.0000 - val_loss: 6.0297e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "13600/13600 [==============================] - 13s 943us/step - loss: 5.7608e-05 - accuracy: 1.0000 - val_loss: 5.2173e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "13600/13600 [==============================] - 13s 945us/step - loss: 5.0558e-05 - accuracy: 1.0000 - val_loss: 4.5890e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "13600/13600 [==============================] - 13s 941us/step - loss: 4.4345e-05 - accuracy: 1.0000 - val_loss: 4.0348e-05 - val_accuracy: 1.0000\n",
      "Epoch 00017: early stopping\n",
      "3400/3400 [==============================] - 2s 706us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   17번 구간 완료\n",
      "\n",
      "\n",
      "   18번 구간 시작\n",
      "\n",
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/200\n",
      "14400/14400 [==============================] - 14s 951us/step - loss: 0.4809 - accuracy: 0.7955 - val_loss: 0.1803 - val_accuracy: 0.9475\n",
      "Epoch 2/200\n",
      "14400/14400 [==============================] - 14s 949us/step - loss: 0.0406 - accuracy: 0.9944 - val_loss: 0.0265 - val_accuracy: 0.9967\n",
      "Epoch 3/200\n",
      "14400/14400 [==============================] - 14s 947us/step - loss: 0.0190 - accuracy: 0.9976 - val_loss: 0.0201 - val_accuracy: 0.9969\n",
      "Epoch 4/200\n",
      "14400/14400 [==============================] - 14s 946us/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
      "Epoch 5/200\n",
      "14400/14400 [==============================] - 14s 955us/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
      "Epoch 6/200\n",
      "14400/14400 [==============================] - 14s 950us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 5.8354e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "14400/14400 [==============================] - 14s 945us/step - loss: 4.2008e-04 - accuracy: 1.0000 - val_loss: 3.3247e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "14400/14400 [==============================] - 14s 938us/step - loss: 2.6085e-04 - accuracy: 1.0000 - val_loss: 2.1775e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "14400/14400 [==============================] - 14s 944us/step - loss: 1.8499e-04 - accuracy: 1.0000 - val_loss: 1.6094e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "14400/14400 [==============================] - 14s 951us/step - loss: 1.3951e-04 - accuracy: 1.0000 - val_loss: 1.2863e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "14400/14400 [==============================] - 14s 949us/step - loss: 1.1309e-04 - accuracy: 1.0000 - val_loss: 1.0040e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "14400/14400 [==============================] - 14s 942us/step - loss: 8.9042e-05 - accuracy: 1.0000 - val_loss: 8.2285e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "14400/14400 [==============================] - 14s 940us/step - loss: 7.3932e-05 - accuracy: 1.0000 - val_loss: 6.8630e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "14400/14400 [==============================] - 13s 936us/step - loss: 0.1131 - accuracy: 0.9803 - val_loss: 0.1076 - val_accuracy: 0.9964\n",
      "Epoch 15/200\n",
      "14400/14400 [==============================] - 14s 940us/step - loss: 0.0335 - accuracy: 0.9974 - val_loss: 0.0229 - val_accuracy: 0.9964\n",
      "Epoch 16/200\n",
      "14400/14400 [==============================] - 13s 937us/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.0219 - val_accuracy: 0.9964\n",
      "Epoch 00016: early stopping\n",
      "3600/3600 [==============================] - 3s 695us/step\n",
      "\n",
      " Test Accuracy: 0.9964\n",
      "   18번 구간 완료\n",
      "\n",
      "\n",
      "   19번 구간 시작\n",
      "\n",
      "Train on 15200 samples, validate on 3800 samples\n",
      "Epoch 1/200\n",
      "15200/15200 [==============================] - 14s 953us/step - loss: 0.4711 - accuracy: 0.8055 - val_loss: 0.0961 - val_accuracy: 0.9689\n",
      "Epoch 2/200\n",
      "15200/15200 [==============================] - 14s 943us/step - loss: 0.0232 - accuracy: 0.9963 - val_loss: 0.0138 - val_accuracy: 0.9971\n",
      "Epoch 3/200\n",
      "15200/15200 [==============================] - 14s 945us/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "15200/15200 [==============================] - 14s 936us/step - loss: 0.0673 - accuracy: 0.9876 - val_loss: 0.0919 - val_accuracy: 0.9966\n",
      "Epoch 5/200\n",
      "15200/15200 [==============================] - 14s 933us/step - loss: 0.0288 - accuracy: 0.9975 - val_loss: 0.0204 - val_accuracy: 0.9966\n",
      "Epoch 6/200\n",
      "15200/15200 [==============================] - 14s 941us/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.0183 - val_accuracy: 0.9966\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15200/15200 [==============================] - 14s 938us/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.0167 - val_accuracy: 0.9968\n",
      "Epoch 8/200\n",
      "15200/15200 [==============================] - 14s 945us/step - loss: 0.0122 - accuracy: 0.9978 - val_loss: 0.0135 - val_accuracy: 0.9968\n",
      "Epoch 00008: early stopping\n",
      "3800/3800 [==============================] - 3s 712us/step\n",
      "\n",
      " Test Accuracy: 0.9968\n",
      "   19번 구간 완료\n",
      "\n",
      "\n",
      "   20번 구간 시작\n",
      "\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/200\n",
      "16000/16000 [==============================] - 15s 949us/step - loss: 0.4295 - accuracy: 0.8309 - val_loss: 0.0269 - val_accuracy: 0.9977\n",
      "Epoch 2/200\n",
      "16000/16000 [==============================] - 15s 931us/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "Epoch 3/200\n",
      "16000/16000 [==============================] - 15s 939us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 4/200\n",
      "16000/16000 [==============================] - 15s 942us/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 7.0935e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "16000/16000 [==============================] - 15s 938us/step - loss: 4.8021e-04 - accuracy: 1.0000 - val_loss: 3.3205e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "16000/16000 [==============================] - 15s 940us/step - loss: 2.6613e-04 - accuracy: 1.0000 - val_loss: 2.0439e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "16000/16000 [==============================] - 15s 940us/step - loss: 1.8131e-04 - accuracy: 1.0000 - val_loss: 1.4715e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "16000/16000 [==============================] - 15s 942us/step - loss: 1.3418e-04 - accuracy: 1.0000 - val_loss: 1.1151e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "16000/16000 [==============================] - 15s 943us/step - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 8.7542e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "16000/16000 [==============================] - 15s 941us/step - loss: 8.2756e-05 - accuracy: 1.0000 - val_loss: 7.1564e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "16000/16000 [==============================] - 15s 928us/step - loss: 6.7826e-05 - accuracy: 1.0000 - val_loss: 5.8914e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "16000/16000 [==============================] - 15s 932us/step - loss: 5.6596e-05 - accuracy: 1.0000 - val_loss: 4.9397e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "16000/16000 [==============================] - 15s 933us/step - loss: 4.7800e-05 - accuracy: 1.0000 - val_loss: 4.1996e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "16000/16000 [==============================] - 15s 934us/step - loss: 4.0962e-05 - accuracy: 1.0000 - val_loss: 3.6209e-05 - val_accuracy: 1.0000\n",
      "Epoch 00014: early stopping\n",
      "4000/4000 [==============================] - 3s 711us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   20번 구간 완료\n",
      "\n",
      "\n",
      "   21번 구간 시작\n",
      "\n",
      "Train on 16800 samples, validate on 4200 samples\n",
      "Epoch 1/200\n",
      "16800/16800 [==============================] - 16s 949us/step - loss: 0.4168 - accuracy: 0.8385 - val_loss: 0.0324 - val_accuracy: 0.9976\n",
      "Epoch 2/200\n",
      "16800/16800 [==============================] - 16s 943us/step - loss: 0.0165 - accuracy: 0.9977 - val_loss: 0.0081 - val_accuracy: 0.9979\n",
      "Epoch 3/200\n",
      "16800/16800 [==============================] - 16s 937us/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0202 - val_accuracy: 0.9931\n",
      "Epoch 4/200\n",
      "16800/16800 [==============================] - 16s 938us/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 5.5257e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "16800/16800 [==============================] - 16s 945us/step - loss: 4.1717e-04 - accuracy: 1.0000 - val_loss: 2.9290e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "16800/16800 [==============================] - 16s 947us/step - loss: 2.4989e-04 - accuracy: 1.0000 - val_loss: 1.9243e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "16800/16800 [==============================] - 16s 943us/step - loss: 1.7047e-04 - accuracy: 1.0000 - val_loss: 1.3565e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "16800/16800 [==============================] - 16s 939us/step - loss: 1.2499e-04 - accuracy: 1.0000 - val_loss: 1.0258e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "16800/16800 [==============================] - 16s 937us/step - loss: 9.5886e-05 - accuracy: 1.0000 - val_loss: 8.0498e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "16800/16800 [==============================] - 16s 940us/step - loss: 7.5956e-05 - accuracy: 1.0000 - val_loss: 6.4626e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "16800/16800 [==============================] - 16s 944us/step - loss: 6.1680e-05 - accuracy: 1.0000 - val_loss: 5.2672e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "16800/16800 [==============================] - 16s 946us/step - loss: 5.0945e-05 - accuracy: 1.0000 - val_loss: 4.4030e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "16800/16800 [==============================] - 16s 934us/step - loss: 4.2727e-05 - accuracy: 1.0000 - val_loss: 3.7144e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "16800/16800 [==============================] - 16s 938us/step - loss: 3.6343e-05 - accuracy: 1.0000 - val_loss: 3.1785e-05 - val_accuracy: 1.0000\n",
      "Epoch 00014: early stopping\n",
      "4200/4200 [==============================] - 3s 703us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   21번 구간 완료\n",
      "\n",
      "\n",
      "   22번 구간 시작\n",
      "\n",
      "Train on 17600 samples, validate on 4400 samples\n",
      "Epoch 1/200\n",
      "17600/17600 [==============================] - 17s 949us/step - loss: 0.4057 - accuracy: 0.8320 - val_loss: 0.0252 - val_accuracy: 0.9973\n",
      "Epoch 2/200\n",
      "17600/17600 [==============================] - 17s 953us/step - loss: 0.0200 - accuracy: 0.9970 - val_loss: 0.0125 - val_accuracy: 0.9982\n",
      "Epoch 3/200\n",
      "17600/17600 [==============================] - 17s 938us/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
      "Epoch 4/200\n",
      "17600/17600 [==============================] - 17s 943us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 8.6694e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "17600/17600 [==============================] - 17s 945us/step - loss: 5.5742e-04 - accuracy: 1.0000 - val_loss: 4.8169e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "17600/17600 [==============================] - 16s 937us/step - loss: 3.4482e-04 - accuracy: 1.0000 - val_loss: 3.3343e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "17600/17600 [==============================] - 17s 943us/step - loss: 2.3765e-04 - accuracy: 1.0000 - val_loss: 2.4389e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "17600/17600 [==============================] - 17s 938us/step - loss: 1.7451e-04 - accuracy: 1.0000 - val_loss: 1.8473e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "17600/17600 [==============================] - 17s 942us/step - loss: 1.3327e-04 - accuracy: 1.0000 - val_loss: 1.4700e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "17600/17600 [==============================] - 16s 928us/step - loss: 1.0535e-04 - accuracy: 1.0000 - val_loss: 1.1893e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "17600/17600 [==============================] - 17s 946us/step - loss: 8.5356e-05 - accuracy: 1.0000 - val_loss: 9.7747e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "17600/17600 [==============================] - 17s 946us/step - loss: 7.0627e-05 - accuracy: 1.0000 - val_loss: 8.2106e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "17600/17600 [==============================] - 17s 942us/step - loss: 5.8944e-05 - accuracy: 1.0000 - val_loss: 7.2589e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "17600/17600 [==============================] - 17s 941us/step - loss: 4.9911e-05 - accuracy: 1.0000 - val_loss: 6.2402e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "17600/17600 [==============================] - 17s 947us/step - loss: 4.2703e-05 - accuracy: 1.0000 - val_loss: 5.5965e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "17600/17600 [==============================] - 17s 938us/step - loss: 3.6882e-05 - accuracy: 1.0000 - val_loss: 4.6979e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "17600/17600 [==============================] - 17s 945us/step - loss: 3.2014e-05 - accuracy: 1.0000 - val_loss: 4.1765e-05 - val_accuracy: 1.0000\n",
      "Epoch 00017: early stopping\n",
      "4400/4400 [==============================] - 3s 699us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   22번 구간 완료\n",
      "\n",
      "\n",
      "   23번 구간 시작\n",
      "\n",
      "Train on 18400 samples, validate on 4600 samples\n",
      "Epoch 1/200\n",
      "18400/18400 [==============================] - 18s 954us/step - loss: 0.3972 - accuracy: 0.8307 - val_loss: 0.0280 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "18400/18400 [==============================] - 17s 940us/step - loss: 0.0183 - accuracy: 0.9974 - val_loss: 0.0037 - val_accuracy: 0.9996\n",
      "Epoch 3/200\n",
      "18400/18400 [==============================] - 17s 943us/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 8.3226e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "18400/18400 [==============================] - 17s 951us/step - loss: 6.2197e-04 - accuracy: 1.0000 - val_loss: 4.4307e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "18400/18400 [==============================] - 17s 943us/step - loss: 3.3890e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
      "Epoch 6/200\n",
      "18400/18400 [==============================] - 17s 948us/step - loss: 2.1999e-04 - accuracy: 1.0000 - val_loss: 2.0407e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "18400/18400 [==============================] - 17s 949us/step - loss: 1.5702e-04 - accuracy: 1.0000 - val_loss: 1.4328e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "18400/18400 [==============================] - 17s 941us/step - loss: 1.1769e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
      "Epoch 9/200\n",
      "18400/18400 [==============================] - 17s 942us/step - loss: 9.3050e-05 - accuracy: 1.0000 - val_loss: 8.5187e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "18400/18400 [==============================] - 17s 947us/step - loss: 7.2892e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
      "Epoch 11/200\n",
      "18400/18400 [==============================] - 17s 939us/step - loss: 5.9964e-05 - accuracy: 1.0000 - val_loss: 5.7651e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "18400/18400 [==============================] - 17s 942us/step - loss: 4.9742e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
      "Epoch 13/200\n",
      "18400/18400 [==============================] - 17s 942us/step - loss: 4.5667e-05 - accuracy: 1.0000 - val_loss: 3.9356e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "18400/18400 [==============================] - 17s 942us/step - loss: 3.5474e-05 - accuracy: 1.0000 - val_loss: 3.4462e-05 - val_accuracy: 1.0000\n",
      "Epoch 00014: early stopping\n",
      "4600/4600 [==============================] - 3s 690us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   23번 구간 완료\n",
      "\n",
      "\n",
      "   24번 구간 시작\n",
      "\n",
      "Train on 19200 samples, validate on 4800 samples\n",
      "Epoch 1/200\n",
      "19200/19200 [==============================] - 18s 956us/step - loss: 0.3682 - accuracy: 0.8490 - val_loss: 0.0301 - val_accuracy: 0.9969\n",
      "Epoch 2/200\n",
      "19200/19200 [==============================] - 18s 940us/step - loss: 0.0298 - accuracy: 0.9969 - val_loss: 0.0216 - val_accuracy: 0.9967\n",
      "Epoch 3/200\n",
      "19200/19200 [==============================] - 18s 940us/step - loss: 0.0161 - accuracy: 0.9974 - val_loss: 0.0109 - val_accuracy: 0.9971\n",
      "Epoch 4/200\n",
      "19200/19200 [==============================] - 18s 941us/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 8.1256e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "19200/19200 [==============================] - 18s 940us/step - loss: 5.5890e-04 - accuracy: 1.0000 - val_loss: 4.9272e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "19200/19200 [==============================] - 18s 939us/step - loss: 3.6574e-04 - accuracy: 1.0000 - val_loss: 3.4239e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "19200/19200 [==============================] - 18s 947us/step - loss: 2.6241e-04 - accuracy: 1.0000 - val_loss: 2.5365e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "19200/19200 [==============================] - 18s 932us/step - loss: 1.9843e-04 - accuracy: 1.0000 - val_loss: 1.9575e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "19200/19200 [==============================] - 18s 937us/step - loss: 1.5567e-04 - accuracy: 1.0000 - val_loss: 1.5626e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "19200/19200 [==============================] - 18s 938us/step - loss: 1.2536e-04 - accuracy: 1.0000 - val_loss: 1.2735e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "19200/19200 [==============================] - 18s 932us/step - loss: 1.0298e-04 - accuracy: 1.0000 - val_loss: 1.0577e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "19200/19200 [==============================] - 18s 940us/step - loss: 8.5995e-05 - accuracy: 1.0000 - val_loss: 8.9128e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "19200/19200 [==============================] - 18s 940us/step - loss: 7.2739e-05 - accuracy: 1.0000 - val_loss: 7.5979e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "19200/19200 [==============================] - 18s 943us/step - loss: 6.2150e-05 - accuracy: 1.0000 - val_loss: 6.5281e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "19200/19200 [==============================] - 18s 941us/step - loss: 5.3567e-05 - accuracy: 1.0000 - val_loss: 5.6688e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "19200/19200 [==============================] - 18s 932us/step - loss: 4.6526e-05 - accuracy: 1.0000 - val_loss: 4.9524e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "19200/19200 [==============================] - 18s 939us/step - loss: 4.0675e-05 - accuracy: 1.0000 - val_loss: 4.3500e-05 - val_accuracy: 1.0000\n",
      "Epoch 00017: early stopping\n",
      "4800/4800 [==============================] - 3s 712us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   24번 구간 완료\n",
      "\n",
      "\n",
      "   25번 구간 시작\n",
      "\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/200\n",
      "20000/20000 [==============================] - 19s 961us/step - loss: 0.3637 - accuracy: 0.8463 - val_loss: 0.0184 - val_accuracy: 0.9972\n",
      "Epoch 2/200\n",
      "20000/20000 [==============================] - 19s 945us/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0087 - val_accuracy: 0.9982\n",
      "Epoch 3/200\n",
      "20000/20000 [==============================] - 19s 953us/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 6.5523e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "20000/20000 [==============================] - 19s 946us/step - loss: 5.0098e-04 - accuracy: 1.0000 - val_loss: 3.3362e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "20000/20000 [==============================] - 19s 946us/step - loss: 2.8006e-04 - accuracy: 1.0000 - val_loss: 2.0555e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "20000/20000 [==============================] - 19s 951us/step - loss: 1.8496e-04 - accuracy: 1.0000 - val_loss: 1.4142e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "20000/20000 [==============================] - 19s 948us/step - loss: 1.3016e-04 - accuracy: 1.0000 - val_loss: 1.0281e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "20000/20000 [==============================] - 19s 945us/step - loss: 9.7045e-05 - accuracy: 1.0000 - val_loss: 7.7887e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "20000/20000 [==============================] - 19s 955us/step - loss: 8.7478e-05 - accuracy: 1.0000 - val_loss: 6.2980e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "20000/20000 [==============================] - 19s 945us/step - loss: 6.0360e-05 - accuracy: 1.0000 - val_loss: 5.0088e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "20000/20000 [==============================] - 19s 946us/step - loss: 4.8294e-05 - accuracy: 1.0000 - val_loss: 4.0451e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "20000/20000 [==============================] - 19s 949us/step - loss: 3.9557e-05 - accuracy: 1.0000 - val_loss: 3.3723e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "5000/5000 [==============================] - 4s 712us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   25번 구간 완료\n",
      "\n",
      "\n",
      "   26번 구간 시작\n",
      "\n",
      "Train on 20800 samples, validate on 5200 samples\n",
      "Epoch 1/200\n",
      "20800/20800 [==============================] - 20s 959us/step - loss: 0.3522 - accuracy: 0.8615 - val_loss: 0.0196 - val_accuracy: 0.9983\n",
      "Epoch 2/200\n",
      "20800/20800 [==============================] - 20s 951us/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
      "Epoch 3/200\n",
      "20800/20800 [==============================] - 20s 938us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1982e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "20800/20800 [==============================] - 20s 945us/step - loss: 4.9339e-04 - accuracy: 1.0000 - val_loss: 3.1381e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "20800/20800 [==============================] - 19s 935us/step - loss: 2.5525e-04 - accuracy: 1.0000 - val_loss: 1.9049e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "20800/20800 [==============================] - 20s 942us/step - loss: 1.5930e-04 - accuracy: 1.0000 - val_loss: 1.2705e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "20800/20800 [==============================] - 20s 943us/step - loss: 1.1162e-04 - accuracy: 1.0000 - val_loss: 9.1532e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "20800/20800 [==============================] - 20s 950us/step - loss: 8.1972e-05 - accuracy: 1.0000 - val_loss: 7.0574e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "20800/20800 [==============================] - 20s 948us/step - loss: 6.4120e-05 - accuracy: 1.0000 - val_loss: 5.3373e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "20800/20800 [==============================] - 19s 934us/step - loss: 4.9564e-05 - accuracy: 1.0000 - val_loss: 4.2865e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "20800/20800 [==============================] - 19s 937us/step - loss: 3.9809e-05 - accuracy: 1.0000 - val_loss: 3.5019e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "20800/20800 [==============================] - 19s 934us/step - loss: 3.2590e-05 - accuracy: 1.0000 - val_loss: 2.8712e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "20800/20800 [==============================] - 19s 937us/step - loss: 2.7515e-05 - accuracy: 1.0000 - val_loss: 2.4137e-05 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "5200/5200 [==============================] - 4s 698us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   26번 구간 완료\n",
      "\n",
      "\n",
      "   27번 구간 시작\n",
      "\n",
      "Train on 21600 samples, validate on 5400 samples\n",
      "Epoch 1/200\n",
      "21600/21600 [==============================] - 21s 967us/step - loss: 0.3740 - accuracy: 0.8463 - val_loss: 0.0138 - val_accuracy: 0.9985\n",
      "Epoch 2/200\n",
      "21600/21600 [==============================] - 21s 953us/step - loss: 0.0243 - accuracy: 0.9964 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 3/200\n",
      "21600/21600 [==============================] - 21s 958us/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 6.6698e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "21600/21600 [==============================] - 20s 948us/step - loss: 5.7359e-04 - accuracy: 1.0000 - val_loss: 3.6185e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "21600/21600 [==============================] - 21s 953us/step - loss: 3.3480e-04 - accuracy: 1.0000 - val_loss: 2.3565e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "21600/21600 [==============================] - 21s 950us/step - loss: 2.2243e-04 - accuracy: 1.0000 - val_loss: 1.6321e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "21600/21600 [==============================] - 20s 947us/step - loss: 1.5916e-04 - accuracy: 1.0000 - val_loss: 1.2004e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "21600/21600 [==============================] - 20s 946us/step - loss: 1.2050e-04 - accuracy: 1.0000 - val_loss: 9.3159e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "21600/21600 [==============================] - 21s 951us/step - loss: 9.3899e-05 - accuracy: 1.0000 - val_loss: 7.3858e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "21600/21600 [==============================] - 21s 951us/step - loss: 7.4899e-05 - accuracy: 1.0000 - val_loss: 5.9311e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "21600/21600 [==============================] - 21s 954us/step - loss: 6.1204e-05 - accuracy: 1.0000 - val_loss: 4.8972e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "21600/21600 [==============================] - 21s 960us/step - loss: 5.0494e-05 - accuracy: 1.0000 - val_loss: 4.0769e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "5400/5400 [==============================] - 4s 700us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   27번 구간 완료\n",
      "\n",
      "\n",
      "   28번 구간 시작\n",
      "\n",
      "Train on 22400 samples, validate on 5600 samples\n",
      "Epoch 1/200\n",
      "22400/22400 [==============================] - 22s 966us/step - loss: 0.3334 - accuracy: 0.8601 - val_loss: 0.0185 - val_accuracy: 0.9968\n",
      "Epoch 2/200\n",
      "22400/22400 [==============================] - 21s 951us/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 3/200\n",
      "22400/22400 [==============================] - 21s 952us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.8507e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "22400/22400 [==============================] - 21s 956us/step - loss: 3.6144e-04 - accuracy: 1.0000 - val_loss: 3.2008e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "22400/22400 [==============================] - 21s 950us/step - loss: 0.1061 - accuracy: 0.9658 - val_loss: 0.2344 - val_accuracy: 0.8659\n",
      "Epoch 6/200\n",
      "22400/22400 [==============================] - 21s 953us/step - loss: 0.2196 - accuracy: 0.8631 - val_loss: 0.2186 - val_accuracy: 0.8659\n",
      "Epoch 7/200\n",
      "22400/22400 [==============================] - 21s 947us/step - loss: 0.1887 - accuracy: 0.8906 - val_loss: 0.0470 - val_accuracy: 0.9848\n",
      "Epoch 8/200\n",
      "22400/22400 [==============================] - 21s 941us/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "22400/22400 [==============================] - 21s 958us/step - loss: 8.7530e-04 - accuracy: 1.0000 - val_loss: 6.8139e-04 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "5600/5600 [==============================] - 4s 709us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   28번 구간 완료\n",
      "\n",
      "\n",
      "   29번 구간 시작\n",
      "\n",
      "Train on 23200 samples, validate on 5800 samples\n",
      "Epoch 1/200\n",
      "23200/23200 [==============================] - 22s 960us/step - loss: 0.3362 - accuracy: 0.8605 - val_loss: 0.0167 - val_accuracy: 0.9976\n",
      "Epoch 2/200\n",
      "23200/23200 [==============================] - 22s 947us/step - loss: 0.0234 - accuracy: 0.9950 - val_loss: 0.0178 - val_accuracy: 0.9974\n",
      "Epoch 3/200\n",
      "23200/23200 [==============================] - 22s 951us/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.0069 - val_accuracy: 0.9976\n",
      "Epoch 4/200\n",
      "23200/23200 [==============================] - 22s 952us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 9.4653e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "23200/23200 [==============================] - 22s 951us/step - loss: 6.5235e-04 - accuracy: 1.0000 - val_loss: 4.5229e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "23200/23200 [==============================] - 22s 943us/step - loss: 3.6456e-04 - accuracy: 1.0000 - val_loss: 2.8237e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "23200/23200 [==============================] - 22s 954us/step - loss: 2.4374e-04 - accuracy: 1.0000 - val_loss: 1.9779e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "23200/23200 [==============================] - 22s 951us/step - loss: 1.7687e-04 - accuracy: 1.0000 - val_loss: 1.4753e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "23200/23200 [==============================] - 22s 941us/step - loss: 1.3496e-04 - accuracy: 1.0000 - val_loss: 1.1441e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "23200/23200 [==============================] - 22s 952us/step - loss: 1.0638e-04 - accuracy: 1.0000 - val_loss: 9.1157e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "23200/23200 [==============================] - 22s 948us/step - loss: 8.5811e-05 - accuracy: 1.0000 - val_loss: 7.4090e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "23200/23200 [==============================] - 22s 952us/step - loss: 7.0423e-05 - accuracy: 1.0000 - val_loss: 6.1048e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "23200/23200 [==============================] - 22s 948us/step - loss: 5.8544e-05 - accuracy: 1.0000 - val_loss: 5.1004e-05 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "5800/5800 [==============================] - 4s 707us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   29번 구간 완료\n",
      "\n",
      "\n",
      "   30번 구간 시작\n",
      "\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/200\n",
      "24000/24000 [==============================] - 23s 945us/step - loss: 0.3143 - accuracy: 0.8684 - val_loss: 0.0143 - val_accuracy: 0.9980\n",
      "Epoch 2/200\n",
      "24000/24000 [==============================] - 23s 950us/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "24000/24000 [==============================] - 23s 946us/step - loss: 9.1336e-04 - accuracy: 1.0000 - val_loss: 4.9666e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "24000/24000 [==============================] - 23s 948us/step - loss: 3.8789e-04 - accuracy: 1.0000 - val_loss: 2.6542e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "24000/24000 [==============================] - 23s 938us/step - loss: 2.2400e-04 - accuracy: 1.0000 - val_loss: 1.6663e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "24000/24000 [==============================] - 23s 946us/step - loss: 1.4673e-04 - accuracy: 1.0000 - val_loss: 1.1526e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "24000/24000 [==============================] - 23s 944us/step - loss: 1.0513e-04 - accuracy: 1.0000 - val_loss: 8.4296e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "24000/24000 [==============================] - 23s 944us/step - loss: 7.8935e-05 - accuracy: 1.0000 - val_loss: 6.4094e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "24000/24000 [==============================] - 23s 948us/step - loss: 6.0050e-05 - accuracy: 1.0000 - val_loss: 5.1307e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "24000/24000 [==============================] - 23s 949us/step - loss: 4.8281e-05 - accuracy: 1.0000 - val_loss: 4.0394e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "24000/24000 [==============================] - 23s 950us/step - loss: 3.8560e-05 - accuracy: 1.0000 - val_loss: 3.2781e-05 - val_accuracy: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "6000/6000 [==============================] - 4s 723us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   30번 구간 완료\n",
      "\n",
      "\n",
      "   31번 구간 시작\n",
      "\n",
      "Train on 24800 samples, validate on 6200 samples\n",
      "Epoch 1/200\n",
      "24800/24800 [==============================] - 24s 951us/step - loss: 0.3123 - accuracy: 0.8736 - val_loss: 0.0211 - val_accuracy: 0.9971\n",
      "Epoch 2/200\n",
      "24800/24800 [==============================] - 23s 947us/step - loss: 0.0238 - accuracy: 0.9966 - val_loss: 0.0316 - val_accuracy: 0.9969\n",
      "Epoch 3/200\n",
      "24800/24800 [==============================] - 23s 943us/step - loss: 0.0168 - accuracy: 0.9975 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "24800/24800 [==============================] - 23s 943us/step - loss: 7.8294e-04 - accuracy: 1.0000 - val_loss: 4.4887e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "24800/24800 [==============================] - 24s 951us/step - loss: 3.4843e-04 - accuracy: 1.0000 - val_loss: 2.5866e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "24800/24800 [==============================] - 24s 951us/step - loss: 2.1618e-04 - accuracy: 1.0000 - val_loss: 1.7024e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "24800/24800 [==============================] - 24s 951us/step - loss: 1.4795e-04 - accuracy: 1.0000 - val_loss: 1.2053e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "24800/24800 [==============================] - 23s 945us/step - loss: 1.0786e-04 - accuracy: 1.0000 - val_loss: 9.0105e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "24800/24800 [==============================] - 24s 948us/step - loss: 8.2180e-05 - accuracy: 1.0000 - val_loss: 6.9767e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "24800/24800 [==============================] - 23s 937us/step - loss: 6.4596e-05 - accuracy: 1.0000 - val_loss: 5.5408e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "24800/24800 [==============================] - 23s 945us/step - loss: 5.1881e-05 - accuracy: 1.0000 - val_loss: 4.4954e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "24800/24800 [==============================] - 24s 948us/step - loss: 4.2467e-05 - accuracy: 1.0000 - val_loss: 3.7064e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "6200/6200 [==============================] - 4s 710us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   31번 구간 완료\n",
      "\n",
      "\n",
      "   32번 구간 시작\n",
      "\n",
      "Train on 25600 samples, validate on 6400 samples\n",
      "Epoch 1/200\n",
      "25600/25600 [==============================] - 25s 962us/step - loss: 0.2910 - accuracy: 0.8794 - val_loss: 0.0136 - val_accuracy: 0.9973\n",
      "Epoch 2/200\n",
      "25600/25600 [==============================] - 24s 949us/step - loss: 0.0404 - accuracy: 0.9939 - val_loss: 0.0110 - val_accuracy: 0.9980\n",
      "Epoch 3/200\n",
      "25600/25600 [==============================] - 24s 941us/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 7.8799e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "25600/25600 [==============================] - 24s 949us/step - loss: 6.0081e-04 - accuracy: 1.0000 - val_loss: 4.0212e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "25600/25600 [==============================] - 24s 950us/step - loss: 3.4111e-04 - accuracy: 1.0000 - val_loss: 2.4928e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "25600/25600 [==============================] - 24s 954us/step - loss: 2.1988e-04 - accuracy: 1.0000 - val_loss: 1.7018e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "25600/25600 [==============================] - 24s 950us/step - loss: 1.5538e-04 - accuracy: 1.0000 - val_loss: 1.2353e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "25600/25600 [==============================] - 24s 949us/step - loss: 1.1507e-04 - accuracy: 1.0000 - val_loss: 9.3202e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "25600/25600 [==============================] - 24s 944us/step - loss: 8.8431e-05 - accuracy: 1.0000 - val_loss: 7.2257e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "25600/25600 [==============================] - 24s 951us/step - loss: 6.9320e-05 - accuracy: 1.0000 - val_loss: 5.7224e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "25600/25600 [==============================] - 24s 954us/step - loss: 5.5611e-05 - accuracy: 1.0000 - val_loss: 4.6565e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "25600/25600 [==============================] - 24s 951us/step - loss: 4.5335e-05 - accuracy: 1.0000 - val_loss: 3.8023e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "6400/6400 [==============================] - 5s 715us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   32번 구간 완료\n",
      "\n",
      "\n",
      "   33번 구간 시작\n",
      "\n",
      "Train on 26400 samples, validate on 6600 samples\n",
      "Epoch 1/200\n",
      "26400/26400 [==============================] - 25s 954us/step - loss: 0.3252 - accuracy: 0.8628 - val_loss: 0.0240 - val_accuracy: 0.9967\n",
      "Epoch 2/200\n",
      "26400/26400 [==============================] - 25s 951us/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.0053 - val_accuracy: 0.9977\n",
      "Epoch 3/200\n",
      "26400/26400 [==============================] - 25s 947us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 4.9271e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "26400/26400 [==============================] - 25s 954us/step - loss: 3.3461e-04 - accuracy: 1.0000 - val_loss: 2.6664e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "26400/26400 [==============================] - 25s 939us/step - loss: 0.0213 - accuracy: 0.9973 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "26400/26400 [==============================] - 25s 943us/step - loss: 8.7087e-04 - accuracy: 1.0000 - val_loss: 5.2426e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "26400/26400 [==============================] - 25s 955us/step - loss: 3.4728e-04 - accuracy: 1.0000 - val_loss: 2.7976e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "26400/26400 [==============================] - 25s 957us/step - loss: 2.0463e-04 - accuracy: 1.0000 - val_loss: 1.8383e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "26400/26400 [==============================] - 25s 955us/step - loss: 1.3976e-04 - accuracy: 1.0000 - val_loss: 1.3161e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "26400/26400 [==============================] - 25s 955us/step - loss: 1.0292e-04 - accuracy: 1.0000 - val_loss: 1.0037e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "26400/26400 [==============================] - 25s 946us/step - loss: 7.9198e-05 - accuracy: 1.0000 - val_loss: 7.8900e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "26400/26400 [==============================] - 25s 956us/step - loss: 6.2767e-05 - accuracy: 1.0000 - val_loss: 6.3848e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "26400/26400 [==============================] - 25s 955us/step - loss: 5.0829e-05 - accuracy: 1.0000 - val_loss: 5.2376e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "26400/26400 [==============================] - 25s 950us/step - loss: 4.1819e-05 - accuracy: 1.0000 - val_loss: 4.3636e-05 - val_accuracy: 1.0000\n",
      "Epoch 00014: early stopping\n",
      "6600/6600 [==============================] - 5s 714us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   33번 구간 완료\n",
      "\n",
      "\n",
      "   34번 구간 시작\n",
      "\n",
      "Train on 27200 samples, validate on 6800 samples\n",
      "Epoch 1/200\n",
      "27200/27200 [==============================] - 26s 962us/step - loss: 0.2869 - accuracy: 0.8767 - val_loss: 0.0151 - val_accuracy: 0.9969\n",
      "Epoch 2/200\n",
      "27200/27200 [==============================] - 26s 950us/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
      "Epoch 3/200\n",
      "27200/27200 [==============================] - 26s 951us/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 6.4371e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "27200/27200 [==============================] - 26s 955us/step - loss: 4.4796e-04 - accuracy: 1.0000 - val_loss: 3.5622e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "27200/27200 [==============================] - 25s 933us/step - loss: 2.6640e-04 - accuracy: 1.0000 - val_loss: 2.2777e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "27200/27200 [==============================] - 25s 935us/step - loss: 1.7682e-04 - accuracy: 1.0000 - val_loss: 1.5757e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27200/27200 [==============================] - 26s 942us/step - loss: 1.2547e-04 - accuracy: 1.0000 - val_loss: 1.1502e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "27200/27200 [==============================] - 26s 942us/step - loss: 9.3064e-05 - accuracy: 1.0000 - val_loss: 8.7182e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "27200/27200 [==============================] - 26s 941us/step - loss: 7.1274e-05 - accuracy: 1.0000 - val_loss: 6.7761e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "27200/27200 [==============================] - 26s 938us/step - loss: 5.5870e-05 - accuracy: 1.0000 - val_loss: 5.3724e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "27200/27200 [==============================] - 26s 949us/step - loss: 4.4537e-05 - accuracy: 1.0000 - val_loss: 4.3260e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "27200/27200 [==============================] - 25s 920us/step - loss: 3.6036e-05 - accuracy: 1.0000 - val_loss: 3.5433e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "6800/6800 [==============================] - 5s 698us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   34번 구간 완료\n",
      "\n",
      "\n",
      "   35번 구간 시작\n",
      "\n",
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 27s 948us/step - loss: 0.2667 - accuracy: 0.8968 - val_loss: 0.0198 - val_accuracy: 0.9964\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 27s 949us/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 27s 951us/step - loss: 5.5670e-04 - accuracy: 1.0000 - val_loss: 3.5558e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 27s 948us/step - loss: 2.2652e-04 - accuracy: 1.0000 - val_loss: 1.7598e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 27s 947us/step - loss: 1.3384e-04 - accuracy: 1.0000 - val_loss: 1.0994e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 26s 942us/step - loss: 8.9060e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9999\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 26s 936us/step - loss: 6.3982e-05 - accuracy: 1.0000 - val_loss: 4.3856e-04 - val_accuracy: 0.9999\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 26s 942us/step - loss: 4.8056e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9999\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 26s 940us/step - loss: 3.7322e-05 - accuracy: 1.0000 - val_loss: 7.4210e-04 - val_accuracy: 0.9999\n",
      "Epoch 00009: early stopping\n",
      "7000/7000 [==============================] - 5s 703us/step\n",
      "\n",
      " Test Accuracy: 0.9999\n",
      "   35번 구간 완료\n",
      "\n",
      "\n",
      "   36번 구간 시작\n",
      "\n",
      "Train on 28800 samples, validate on 7200 samples\n",
      "Epoch 1/200\n",
      "28800/28800 [==============================] - 27s 947us/step - loss: 0.2260 - accuracy: 0.9126 - val_loss: 0.0127 - val_accuracy: 0.9972\n",
      "Epoch 2/200\n",
      "28800/28800 [==============================] - 27s 939us/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0037 - val_accuracy: 0.9979\n",
      "Epoch 3/200\n",
      "28800/28800 [==============================] - 27s 943us/step - loss: 0.0309 - accuracy: 0.9948 - val_loss: 0.0173 - val_accuracy: 0.9971\n",
      "Epoch 4/200\n",
      "28800/28800 [==============================] - 27s 937us/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 5/200\n",
      "28800/28800 [==============================] - 27s 945us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 3.7368e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "28800/28800 [==============================] - 27s 942us/step - loss: 2.7713e-04 - accuracy: 1.0000 - val_loss: 2.2221e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "28800/28800 [==============================] - 27s 938us/step - loss: 1.8228e-04 - accuracy: 1.0000 - val_loss: 1.5929e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "28800/28800 [==============================] - 27s 943us/step - loss: 1.3370e-04 - accuracy: 1.0000 - val_loss: 1.1909e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "28800/28800 [==============================] - 27s 945us/step - loss: 1.0289e-04 - accuracy: 1.0000 - val_loss: 9.2639e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "28800/28800 [==============================] - 27s 942us/step - loss: 8.1424e-05 - accuracy: 1.0000 - val_loss: 7.4056e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "28800/28800 [==============================] - 27s 940us/step - loss: 6.5735e-05 - accuracy: 1.0000 - val_loss: 6.0296e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "28800/28800 [==============================] - 27s 942us/step - loss: 5.3895e-05 - accuracy: 1.0000 - val_loss: 4.9649e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "28800/28800 [==============================] - 27s 940us/step - loss: 4.4733e-05 - accuracy: 1.0000 - val_loss: 4.1454e-05 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "7200/7200 [==============================] - 5s 703us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   36번 구간 완료\n",
      "\n",
      "\n",
      "   37번 구간 시작\n",
      "\n",
      "Train on 29600 samples, validate on 7400 samples\n",
      "Epoch 1/200\n",
      "29600/29600 [==============================] - 28s 959us/step - loss: 0.2485 - accuracy: 0.9056 - val_loss: 0.0247 - val_accuracy: 0.9965\n",
      "Epoch 2/200\n",
      "29600/29600 [==============================] - 28s 961us/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.0079 - val_accuracy: 0.9977\n",
      "Epoch 3/200\n",
      "29600/29600 [==============================] - 28s 952us/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.7553e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "29600/29600 [==============================] - 28s 955us/step - loss: 2.4469e-04 - accuracy: 1.0000 - val_loss: 1.7341e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "29600/29600 [==============================] - 28s 954us/step - loss: 1.3286e-04 - accuracy: 1.0000 - val_loss: 1.0236e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "29600/29600 [==============================] - 28s 957us/step - loss: 1.3620e-04 - accuracy: 1.0000 - val_loss: 1.3435e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "29600/29600 [==============================] - 28s 954us/step - loss: 8.5694e-05 - accuracy: 1.0000 - val_loss: 6.4696e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "29600/29600 [==============================] - 28s 944us/step - loss: 5.0691e-05 - accuracy: 1.0000 - val_loss: 4.2384e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "29600/29600 [==============================] - 28s 933us/step - loss: 3.5050e-05 - accuracy: 1.0000 - val_loss: 3.0459e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "29600/29600 [==============================] - 28s 937us/step - loss: 2.6073e-05 - accuracy: 1.0000 - val_loss: 2.3171e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "29600/29600 [==============================] - 28s 937us/step - loss: 2.0201e-05 - accuracy: 1.0000 - val_loss: 1.8147e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "29600/29600 [==============================] - 28s 932us/step - loss: 1.6097e-05 - accuracy: 1.0000 - val_loss: 1.4597e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "7400/7400 [==============================] - 5s 699us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   37번 구간 완료\n",
      "\n",
      "\n",
      "   38번 구간 시작\n",
      "\n",
      "Train on 30400 samples, validate on 7600 samples\n",
      "Epoch 1/200\n",
      "30400/30400 [==============================] - 29s 954us/step - loss: 0.2234 - accuracy: 0.9140 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 2/200\n",
      "30400/30400 [==============================] - 28s 936us/step - loss: 0.2310 - accuracy: 0.8759 - val_loss: 0.2134 - val_accuracy: 0.8632\n",
      "Epoch 3/200\n",
      "30400/30400 [==============================] - 29s 949us/step - loss: 0.0940 - accuracy: 0.9564 - val_loss: 0.2049 - val_accuracy: 0.9562\n",
      "Epoch 4/200\n",
      "30400/30400 [==============================] - 29s 943us/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "30400/30400 [==============================] - 29s 944us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.6419e-04 - val_accuracy: 0.9999\n",
      "Epoch 6/200\n",
      "30400/30400 [==============================] - 29s 944us/step - loss: 5.4188e-04 - accuracy: 1.0000 - val_loss: 5.0100e-04 - val_accuracy: 0.9999\n",
      "Epoch 7/200\n",
      "30400/30400 [==============================] - 29s 941us/step - loss: 3.3935e-04 - accuracy: 1.0000 - val_loss: 3.0881e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "30400/30400 [==============================] - 29s 943us/step - loss: 2.3551e-04 - accuracy: 1.0000 - val_loss: 2.7719e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "30400/30400 [==============================] - 29s 941us/step - loss: 1.7391e-04 - accuracy: 1.0000 - val_loss: 2.2273e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "30400/30400 [==============================] - 29s 941us/step - loss: 1.3258e-04 - accuracy: 1.0000 - val_loss: 2.0140e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "30400/30400 [==============================] - 29s 940us/step - loss: 1.0528e-04 - accuracy: 1.0000 - val_loss: 1.2808e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "30400/30400 [==============================] - 29s 943us/step - loss: 8.4567e-05 - accuracy: 1.0000 - val_loss: 1.2575e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "30400/30400 [==============================] - 29s 942us/step - loss: 6.9121e-05 - accuracy: 1.0000 - val_loss: 1.0604e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "30400/30400 [==============================] - 28s 933us/step - loss: 5.6968e-05 - accuracy: 1.0000 - val_loss: 9.7838e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "30400/30400 [==============================] - 28s 928us/step - loss: 4.7663e-05 - accuracy: 1.0000 - val_loss: 8.5252e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "30400/30400 [==============================] - 28s 922us/step - loss: 4.0086e-05 - accuracy: 1.0000 - val_loss: 6.5614e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "30400/30400 [==============================] - 28s 925us/step - loss: 3.3919e-05 - accuracy: 1.0000 - val_loss: 6.3909e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "30400/30400 [==============================] - 28s 925us/step - loss: 2.8958e-05 - accuracy: 1.0000 - val_loss: 5.5739e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "30400/30400 [==============================] - 29s 938us/step - loss: 2.4816e-05 - accuracy: 1.0000 - val_loss: 5.4693e-05 - val_accuracy: 1.0000\n",
      "Epoch 00019: early stopping\n",
      "7600/7600 [==============================] - 5s 705us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   38번 구간 완료\n",
      "\n",
      "\n",
      "   39번 구간 시작\n",
      "\n",
      "Train on 31200 samples, validate on 7800 samples\n",
      "Epoch 1/200\n",
      "31200/31200 [==============================] - 29s 944us/step - loss: 0.2493 - accuracy: 0.9053 - val_loss: 0.0095 - val_accuracy: 0.9972\n",
      "Epoch 2/200\n",
      "31200/31200 [==============================] - 30s 947us/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 5.4046e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "31200/31200 [==============================] - 29s 944us/step - loss: 3.4534e-04 - accuracy: 1.0000 - val_loss: 2.3261e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "31200/31200 [==============================] - 30s 950us/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0181 - val_accuracy: 0.9971\n",
      "Epoch 5/200\n",
      "31200/31200 [==============================] - 29s 939us/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 6.5588e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "31200/31200 [==============================] - 29s 944us/step - loss: 3.3917e-04 - accuracy: 1.0000 - val_loss: 2.1049e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "31200/31200 [==============================] - 30s 952us/step - loss: 1.5252e-04 - accuracy: 1.0000 - val_loss: 1.2036e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "31200/31200 [==============================] - 29s 938us/step - loss: 9.5102e-05 - accuracy: 1.0000 - val_loss: 8.0616e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "31200/31200 [==============================] - 29s 938us/step - loss: 6.6702e-05 - accuracy: 1.0000 - val_loss: 5.8653e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "31200/31200 [==============================] - 30s 949us/step - loss: 4.9765e-05 - accuracy: 1.0000 - val_loss: 4.4682e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "31200/31200 [==============================] - 29s 944us/step - loss: 3.8579e-05 - accuracy: 1.0000 - val_loss: 3.5113e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "31200/31200 [==============================] - 29s 944us/step - loss: 3.0645e-05 - accuracy: 1.0000 - val_loss: 2.8134e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "7800/7800 [==============================] - 6s 712us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   39번 구간 완료\n",
      "\n",
      "\n",
      "   40번 구간 시작\n",
      "\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/200\n",
      "32000/32000 [==============================] - 30s 944us/step - loss: 0.2315 - accuracy: 0.9144 - val_loss: 0.0386 - val_accuracy: 0.9967\n",
      "Epoch 2/200\n",
      "32000/32000 [==============================] - 30s 943us/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0151 - val_accuracy: 0.9975\n",
      "Epoch 3/200\n",
      "32000/32000 [==============================] - 30s 945us/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "32000/32000 [==============================] - 30s 944us/step - loss: 6.5167e-04 - accuracy: 1.0000 - val_loss: 3.2230e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "32000/32000 [==============================] - 30s 941us/step - loss: 2.5009e-04 - accuracy: 1.0000 - val_loss: 1.7936e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "32000/32000 [==============================] - 30s 948us/step - loss: 1.5160e-04 - accuracy: 1.0000 - val_loss: 1.1750e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "32000/32000 [==============================] - 30s 948us/step - loss: 1.0337e-04 - accuracy: 1.0000 - val_loss: 8.3347e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "32000/32000 [==============================] - 30s 943us/step - loss: 7.5183e-05 - accuracy: 1.0000 - val_loss: 6.2258e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "32000/32000 [==============================] - 30s 948us/step - loss: 5.6920e-05 - accuracy: 1.0000 - val_loss: 4.7925e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "32000/32000 [==============================] - 30s 947us/step - loss: 4.4471e-05 - accuracy: 1.0000 - val_loss: 3.7914e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "32000/32000 [==============================] - 30s 944us/step - loss: 3.5552e-05 - accuracy: 1.0000 - val_loss: 3.0539e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "32000/32000 [==============================] - 30s 945us/step - loss: 2.8905e-05 - accuracy: 1.0000 - val_loss: 2.4984e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "32000/32000 [==============================] - 30s 946us/step - loss: 2.3807e-05 - accuracy: 1.0000 - val_loss: 2.0634e-05 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "8000/8000 [==============================] - 6s 705us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   40번 구간 완료\n",
      "\n",
      "\n",
      "   41번 구간 시작\n",
      "\n",
      "Train on 32800 samples, validate on 8200 samples\n",
      "Epoch 1/200\n",
      "32800/32800 [==============================] - 31s 955us/step - loss: 0.2451 - accuracy: 0.9010 - val_loss: 0.0116 - val_accuracy: 0.9972\n",
      "Epoch 2/200\n",
      "32800/32800 [==============================] - 31s 940us/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.0175 - val_accuracy: 0.9971\n",
      "Epoch 3/200\n",
      "32800/32800 [==============================] - 31s 932us/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.0043 - val_accuracy: 0.9979\n",
      "Epoch 4/200\n",
      "32800/32800 [==============================] - 31s 933us/step - loss: 9.5971e-04 - accuracy: 0.9998 - val_loss: 3.1722e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "32800/32800 [==============================] - 31s 934us/step - loss: 2.3220e-04 - accuracy: 1.0000 - val_loss: 1.6209e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "32800/32800 [==============================] - 31s 948us/step - loss: 1.3417e-04 - accuracy: 1.0000 - val_loss: 1.0237e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "32800/32800 [==============================] - 31s 955us/step - loss: 8.9248e-05 - accuracy: 1.0000 - val_loss: 7.0950e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "32800/32800 [==============================] - 31s 946us/step - loss: 6.3679e-05 - accuracy: 1.0000 - val_loss: 5.1721e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "32800/32800 [==============================] - 31s 945us/step - loss: 4.7581e-05 - accuracy: 1.0000 - val_loss: 3.9235e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "32800/32800 [==============================] - 31s 949us/step - loss: 3.6679e-05 - accuracy: 1.0000 - val_loss: 3.0565e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "32800/32800 [==============================] - 31s 951us/step - loss: 2.8875e-05 - accuracy: 1.0000 - val_loss: 2.4222e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "32800/32800 [==============================] - 31s 950us/step - loss: 2.3131e-05 - accuracy: 1.0000 - val_loss: 1.9568e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32800/32800 [==============================] - 31s 952us/step - loss: 1.8760e-05 - accuracy: 1.0000 - val_loss: 1.5942e-05 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "8200/8200 [==============================] - 6s 700us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   41번 구간 완료\n",
      "\n",
      "\n",
      "   42번 구간 시작\n",
      "\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/200\n",
      "33600/33600 [==============================] - 32s 954us/step - loss: 0.2348 - accuracy: 0.9001 - val_loss: 0.0158 - val_accuracy: 0.9968\n",
      "Epoch 2/200\n",
      "33600/33600 [==============================] - 32s 953us/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.0201 - val_accuracy: 0.9964\n",
      "Epoch 3/200\n",
      "33600/33600 [==============================] - 32s 944us/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "33600/33600 [==============================] - 32s 949us/step - loss: 4.8242e-04 - accuracy: 1.0000 - val_loss: 2.8898e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "33600/33600 [==============================] - 32s 950us/step - loss: 1.9794e-04 - accuracy: 1.0000 - val_loss: 1.5831e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "33600/33600 [==============================] - 32s 946us/step - loss: 1.2269e-04 - accuracy: 1.0000 - val_loss: 1.0551e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "33600/33600 [==============================] - 32s 955us/step - loss: 8.6521e-05 - accuracy: 1.0000 - val_loss: 7.6742e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "33600/33600 [==============================] - 32s 941us/step - loss: 6.4843e-05 - accuracy: 1.0000 - val_loss: 5.8218e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "33600/33600 [==============================] - 32s 954us/step - loss: 5.0231e-05 - accuracy: 1.0000 - val_loss: 4.5689e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "33600/33600 [==============================] - 32s 950us/step - loss: 3.9787e-05 - accuracy: 1.0000 - val_loss: 3.6416e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "33600/33600 [==============================] - 32s 949us/step - loss: 3.2013e-05 - accuracy: 1.0000 - val_loss: 2.9484e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "33600/33600 [==============================] - 32s 948us/step - loss: 2.6066e-05 - accuracy: 1.0000 - val_loss: 2.4078e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "33600/33600 [==============================] - 32s 954us/step - loss: 2.1434e-05 - accuracy: 1.0000 - val_loss: 1.9838e-05 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "8400/8400 [==============================] - 6s 705us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   42번 구간 완료\n",
      "\n",
      "\n",
      "   43번 구간 시작\n",
      "\n",
      "Train on 34400 samples, validate on 8600 samples\n",
      "Epoch 1/200\n",
      "34400/34400 [==============================] - 33s 963us/step - loss: 0.2240 - accuracy: 0.9059 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 2/200\n",
      "34400/34400 [==============================] - 33s 946us/step - loss: 0.0193 - accuracy: 0.9966 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 3/200\n",
      "34400/34400 [==============================] - 33s 954us/step - loss: 8.5150e-04 - accuracy: 0.9999 - val_loss: 4.1532e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "34400/34400 [==============================] - 33s 948us/step - loss: 2.9871e-04 - accuracy: 1.0000 - val_loss: 2.3226e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "34400/34400 [==============================] - 33s 945us/step - loss: 1.7513e-04 - accuracy: 1.0000 - val_loss: 1.4671e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "34400/34400 [==============================] - 32s 945us/step - loss: 1.1359e-04 - accuracy: 1.0000 - val_loss: 9.9358e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "34400/34400 [==============================] - 33s 951us/step - loss: 7.8577e-05 - accuracy: 1.0000 - val_loss: 7.1683e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "34400/34400 [==============================] - 33s 950us/step - loss: 5.6989e-05 - accuracy: 1.0000 - val_loss: 5.3429e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "34400/34400 [==============================] - 33s 950us/step - loss: 4.2770e-05 - accuracy: 1.0000 - val_loss: 4.0684e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "34400/34400 [==============================] - 33s 946us/step - loss: 3.2925e-05 - accuracy: 1.0000 - val_loss: 3.1827e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "34400/34400 [==============================] - 33s 948us/step - loss: 2.5863e-05 - accuracy: 1.0000 - val_loss: 2.5497e-05 - val_accuracy: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "8600/8600 [==============================] - ETA:  - 6s 711us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   43번 구간 완료\n",
      "\n",
      "\n",
      "   44번 구간 시작\n",
      "\n",
      "Train on 35200 samples, validate on 8800 samples\n",
      "Epoch 1/200\n",
      "35200/35200 [==============================] - 34s 952us/step - loss: 0.2179 - accuracy: 0.9143 - val_loss: 0.0151 - val_accuracy: 0.9980\n",
      "Epoch 2/200\n",
      "35200/35200 [==============================] - 33s 946us/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 8.5781e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "35200/35200 [==============================] - 33s 948us/step - loss: 5.1970e-04 - accuracy: 1.0000 - val_loss: 3.5008e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "35200/35200 [==============================] - 33s 943us/step - loss: 2.4097e-04 - accuracy: 1.0000 - val_loss: 1.8889e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "35200/35200 [==============================] - 33s 941us/step - loss: 1.3949e-04 - accuracy: 1.0000 - val_loss: 1.1912e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "35200/35200 [==============================] - 33s 947us/step - loss: 9.0260e-05 - accuracy: 1.0000 - val_loss: 8.1451e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "35200/35200 [==============================] - 33s 949us/step - loss: 6.2697e-05 - accuracy: 1.0000 - val_loss: 5.8863e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "35200/35200 [==============================] - 33s 943us/step - loss: 4.5575e-05 - accuracy: 1.0000 - val_loss: 4.3553e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "35200/35200 [==============================] - 33s 944us/step - loss: 3.4225e-05 - accuracy: 1.0000 - val_loss: 3.3839e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "35200/35200 [==============================] - 33s 942us/step - loss: 2.6427e-05 - accuracy: 1.0000 - val_loss: 2.6686e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "35200/35200 [==============================] - 33s 946us/step - loss: 2.0740e-05 - accuracy: 1.0000 - val_loss: 2.1052e-05 - val_accuracy: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "8800/8800 [==============================] - 6s 708us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   44번 구간 완료\n",
      "\n",
      "\n",
      "   45번 구간 시작\n",
      "\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "36000/36000 [==============================] - 34s 953us/step - loss: 0.3243 - accuracy: 0.8521 - val_loss: 0.2164 - val_accuracy: 0.8681\n",
      "Epoch 2/200\n",
      "36000/36000 [==============================] - 35s 960us/step - loss: 0.1488 - accuracy: 0.9330 - val_loss: 0.0236 - val_accuracy: 0.9953\n",
      "Epoch 3/200\n",
      "36000/36000 [==============================] - 34s 955us/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "36000/36000 [==============================] - 35s 970us/step - loss: 9.7715e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 5/200\n",
      "36000/36000 [==============================] - 34s 957us/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 5.6112e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "36000/36000 [==============================] - 35s 958us/step - loss: 3.9126e-04 - accuracy: 1.0000 - val_loss: 3.0187e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "36000/36000 [==============================] - 35s 960us/step - loss: 2.3548e-04 - accuracy: 1.0000 - val_loss: 1.9482e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "36000/36000 [==============================] - 34s 958us/step - loss: 1.6042e-04 - accuracy: 1.0000 - val_loss: 1.3589e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "36000/36000 [==============================] - 35s 962us/step - loss: 1.1610e-04 - accuracy: 1.0000 - val_loss: 9.9674e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "36000/36000 [==============================] - 35s 959us/step - loss: 8.6964e-05 - accuracy: 1.0000 - val_loss: 7.5074e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "36000/36000 [==============================] - 34s 952us/step - loss: 6.6933e-05 - accuracy: 1.0000 - val_loss: 5.7899e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 35s 962us/step - loss: 5.2550e-05 - accuracy: 1.0000 - val_loss: 4.5812e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "36000/36000 [==============================] - 34s 956us/step - loss: 4.1853e-05 - accuracy: 1.0000 - val_loss: 3.6476e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "36000/36000 [==============================] - 34s 954us/step - loss: 3.3674e-05 - accuracy: 1.0000 - val_loss: 2.9571e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "36000/36000 [==============================] - 34s 950us/step - loss: 2.7356e-05 - accuracy: 1.0000 - val_loss: 2.4087e-05 - val_accuracy: 1.0000\n",
      "Epoch 00015: early stopping\n",
      "9000/9000 [==============================] - 6s 704us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   45번 구간 완료\n",
      "\n",
      "\n",
      "   46번 구간 시작\n",
      "\n",
      "Train on 36800 samples, validate on 9200 samples\n",
      "Epoch 1/200\n",
      "36800/36800 [==============================] - 35s 963us/step - loss: 0.2332 - accuracy: 0.9054 - val_loss: 0.0207 - val_accuracy: 0.9968\n",
      "Epoch 2/200\n",
      "36800/36800 [==============================] - 35s 962us/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "36800/36800 [==============================] - 35s 957us/step - loss: 6.3803e-04 - accuracy: 1.0000 - val_loss: 3.3253e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "36800/36800 [==============================] - 35s 958us/step - loss: 2.3936e-04 - accuracy: 1.0000 - val_loss: 1.6672e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "36800/36800 [==============================] - 35s 960us/step - loss: 1.3744e-04 - accuracy: 1.0000 - val_loss: 1.0415e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "36800/36800 [==============================] - 35s 959us/step - loss: 0.0410 - accuracy: 0.9951 - val_loss: 0.0314 - val_accuracy: 0.9970\n",
      "Epoch 7/200\n",
      "36800/36800 [==============================] - 35s 961us/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 8.5614e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "36800/36800 [==============================] - 35s 959us/step - loss: 5.2631e-04 - accuracy: 1.0000 - val_loss: 3.3489e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "36800/36800 [==============================] - 35s 962us/step - loss: 2.5203e-04 - accuracy: 1.0000 - val_loss: 1.9205e-04 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "9200/9200 [==============================] - 7s 710us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   46번 구간 완료\n",
      "\n",
      "\n",
      "   47번 구간 시작\n",
      "\n",
      "Train on 37600 samples, validate on 9400 samples\n",
      "Epoch 1/200\n",
      "37600/37600 [==============================] - 36s 963us/step - loss: 0.1920 - accuracy: 0.9271 - val_loss: 0.0172 - val_accuracy: 0.9970\n",
      "Epoch 2/200\n",
      "37600/37600 [==============================] - 36s 960us/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 9.8510e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "37600/37600 [==============================] - 36s 960us/step - loss: 4.7439e-04 - accuracy: 1.0000 - val_loss: 2.8981e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "37600/37600 [==============================] - 36s 952us/step - loss: 1.9779e-04 - accuracy: 1.0000 - val_loss: 1.5260e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "37600/37600 [==============================] - 36s 953us/step - loss: 1.1230e-04 - accuracy: 1.0000 - val_loss: 9.3694e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "37600/37600 [==============================] - 36s 961us/step - loss: 7.2604e-05 - accuracy: 1.0000 - val_loss: 6.2359e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "37600/37600 [==============================] - 36s 962us/step - loss: 5.0011e-05 - accuracy: 1.0000 - val_loss: 4.4519e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "37600/37600 [==============================] - 36s 959us/step - loss: 3.6252e-05 - accuracy: 1.0000 - val_loss: 3.3016e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "37600/37600 [==============================] - 36s 950us/step - loss: 2.7190e-05 - accuracy: 1.0000 - val_loss: 2.4841e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "37600/37600 [==============================] - 36s 967us/step - loss: 2.0876e-05 - accuracy: 1.0000 - val_loss: 1.9315e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "37600/37600 [==============================] - 36s 952us/step - loss: 1.6366e-05 - accuracy: 1.0000 - val_loss: 1.5251e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "37600/37600 [==============================] - 35s 941us/step - loss: 1.3029e-05 - accuracy: 1.0000 - val_loss: 1.2169e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "9400/9400 [==============================] - 7s 718us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   47번 구간 완료\n",
      "\n",
      "\n",
      "   48번 구간 시작\n",
      "\n",
      "Train on 38400 samples, validate on 9600 samples\n",
      "Epoch 1/200\n",
      "38400/38400 [==============================] - 37s 957us/step - loss: 0.1950 - accuracy: 0.9193 - val_loss: 0.0077 - val_accuracy: 0.9991\n",
      "Epoch 2/200\n",
      "38400/38400 [==============================] - 37s 960us/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 3/200\n",
      "38400/38400 [==============================] - 37s 952us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.5734e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "38400/38400 [==============================] - 37s 960us/step - loss: 5.3272e-04 - accuracy: 1.0000 - val_loss: 3.7454e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "38400/38400 [==============================] - 37s 960us/step - loss: 2.7157e-04 - accuracy: 1.0000 - val_loss: 2.1837e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "38400/38400 [==============================] - 36s 946us/step - loss: 1.6904e-04 - accuracy: 1.0000 - val_loss: 1.4314e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "38400/38400 [==============================] - 36s 942us/step - loss: 1.1583e-04 - accuracy: 1.0000 - val_loss: 1.0115e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "38400/38400 [==============================] - 36s 947us/step - loss: 8.4155e-05 - accuracy: 1.0000 - val_loss: 7.4798e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "38400/38400 [==============================] - 37s 964us/step - loss: 6.3680e-05 - accuracy: 1.0000 - val_loss: 5.7157e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "38400/38400 [==============================] - 37s 965us/step - loss: 4.9680e-05 - accuracy: 1.0000 - val_loss: 4.4914e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "38400/38400 [==============================] - 37s 954us/step - loss: 3.9637e-05 - accuracy: 1.0000 - val_loss: 3.5793e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "38400/38400 [==============================] - 37s 961us/step - loss: 3.1960e-05 - accuracy: 1.0000 - val_loss: 2.8887e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "9600/9600 [==============================] - 7s 707us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   48번 구간 완료\n",
      "\n",
      "\n",
      "   49번 구간 시작\n",
      "\n",
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/200\n",
      "39200/39200 [==============================] - 38s 964us/step - loss: 0.1958 - accuracy: 0.9226 - val_loss: 0.0140 - val_accuracy: 0.9976\n",
      "Epoch 2/200\n",
      "39200/39200 [==============================] - 38s 962us/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 4.9980e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "39200/39200 [==============================] - 38s 961us/step - loss: 3.0263e-04 - accuracy: 1.0000 - val_loss: 1.9936e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "39200/39200 [==============================] - 38s 961us/step - loss: 1.3794e-04 - accuracy: 1.0000 - val_loss: 1.0853e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "39200/39200 [==============================] - 38s 965us/step - loss: 7.9573e-05 - accuracy: 1.0000 - val_loss: 6.5301e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "39200/39200 [==============================] - 38s 962us/step - loss: 5.1585e-05 - accuracy: 1.0000 - val_loss: 4.3800e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "39200/39200 [==============================] - 38s 964us/step - loss: 3.5690e-05 - accuracy: 1.0000 - val_loss: 3.2398e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "39200/39200 [==============================] - 38s 967us/step - loss: 2.6292e-05 - accuracy: 1.0000 - val_loss: 2.3792e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "39200/39200 [==============================] - 38s 958us/step - loss: 1.9996e-05 - accuracy: 1.0000 - val_loss: 1.7806e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "39200/39200 [==============================] - 37s 951us/step - loss: 1.5680e-05 - accuracy: 1.0000 - val_loss: 1.3877e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "9800/9800 [==============================] - 7s 722us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 1.0000\n",
      "   49번 구간 완료\n",
      "\n",
      "\n",
      "   50번 구간 시작\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "40000/40000 [==============================] - 39s 963us/step - loss: 0.1970 - accuracy: 0.9281 - val_loss: 0.0219 - val_accuracy: 0.9971\n",
      "Epoch 2/200\n",
      "40000/40000 [==============================] - 39s 968us/step - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.0180 - val_accuracy: 0.9971\n",
      "Epoch 3/200\n",
      "40000/40000 [==============================] - 38s 960us/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.0211 - val_accuracy: 0.9963\n",
      "Epoch 4/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 0.0275 - accuracy: 0.9968 - val_loss: 0.0172 - val_accuracy: 0.9971\n",
      "Epoch 5/200\n",
      "40000/40000 [==============================] - 38s 955us/step - loss: 0.0171 - accuracy: 0.9970 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 6/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 4.8406e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 9.4494e-04 - accuracy: 0.9999 - val_loss: 2.1770e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 1.6886e-04 - accuracy: 1.0000 - val_loss: 1.2310e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "40000/40000 [==============================] - 38s 962us/step - loss: 1.0165e-04 - accuracy: 1.0000 - val_loss: 7.9280e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "40000/40000 [==============================] - 39s 968us/step - loss: 6.8060e-05 - accuracy: 1.0000 - val_loss: 5.5132e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 4.8398e-05 - accuracy: 1.0000 - val_loss: 4.0965e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "40000/40000 [==============================] - 38s 961us/step - loss: 3.5839e-05 - accuracy: 1.0000 - val_loss: 3.0324e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "40000/40000 [==============================] - 38s 949us/step - loss: 2.7254e-05 - accuracy: 1.0000 - val_loss: 2.3370e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "40000/40000 [==============================] - 38s 941us/step - loss: 2.1142e-05 - accuracy: 1.0000 - val_loss: 1.8288e-05 - val_accuracy: 1.0000\n",
      "Epoch 00015: early stopping\n",
      "10000/10000 [==============================] - 7s 705us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   50번 구간 완료\n",
      "\n",
      "\n",
      "   51번 구간 시작\n",
      "\n",
      "Train on 40800 samples, validate on 10200 samples\n",
      "Epoch 1/200\n",
      "40800/40800 [==============================] - 40s 968us/step - loss: 0.1901 - accuracy: 0.9254 - val_loss: 0.0125 - val_accuracy: 0.9974\n",
      "Epoch 2/200\n",
      "40800/40800 [==============================] - 39s 960us/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 5.6883e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "40800/40800 [==============================] - 39s 964us/step - loss: 3.6853e-04 - accuracy: 1.0000 - val_loss: 3.8838e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/200\n",
      "40800/40800 [==============================] - 40s 968us/step - loss: 0.0519 - accuracy: 0.9906 - val_loss: 0.0206 - val_accuracy: 0.9968\n",
      "Epoch 5/200\n",
      "40800/40800 [==============================] - 39s 960us/step - loss: 0.0172 - accuracy: 0.9972 - val_loss: 0.0176 - val_accuracy: 0.9968\n",
      "Epoch 6/200\n",
      "40800/40800 [==============================] - 40s 969us/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 8.5948e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "40800/40800 [==============================] - 39s 954us/step - loss: 4.0977e-04 - accuracy: 1.0000 - val_loss: 2.2925e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "40800/40800 [==============================] - 39s 955us/step - loss: 1.8143e-04 - accuracy: 1.0000 - val_loss: 1.3504e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "40800/40800 [==============================] - 39s 964us/step - loss: 1.1514e-04 - accuracy: 1.0000 - val_loss: 9.1262e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "40800/40800 [==============================] - 39s 963us/step - loss: 8.0555e-05 - accuracy: 1.0000 - val_loss: 6.5688e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "40800/40800 [==============================] - 39s 949us/step - loss: 5.9005e-05 - accuracy: 1.0000 - val_loss: 4.9157e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "40800/40800 [==============================] - 40s 970us/step - loss: 4.4697e-05 - accuracy: 1.0000 - val_loss: 3.7659e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "40800/40800 [==============================] - 40s 971us/step - loss: 3.4683e-05 - accuracy: 1.0000 - val_loss: 2.9530e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "40800/40800 [==============================] - 39s 967us/step - loss: 2.7449e-05 - accuracy: 1.0000 - val_loss: 2.3587e-05 - val_accuracy: 1.0000\n",
      "Epoch 00014: early stopping\n",
      "10200/10200 [==============================] - 7s 700us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   51번 구간 완료\n",
      "\n",
      "\n",
      "   52번 구간 시작\n",
      "\n",
      "Train on 41600 samples, validate on 10400 samples\n",
      "Epoch 1/200\n",
      "41600/41600 [==============================] - 40s 967us/step - loss: 0.1633 - accuracy: 0.9384 - val_loss: 0.0224 - val_accuracy: 0.9964\n",
      "Epoch 2/200\n",
      "41600/41600 [==============================] - 40s 955us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 8.8234e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "41600/41600 [==============================] - 40s 958us/step - loss: 4.0343e-04 - accuracy: 1.0000 - val_loss: 2.8015e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "41600/41600 [==============================] - 40s 962us/step - loss: 1.7301e-04 - accuracy: 1.0000 - val_loss: 1.4289e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "41600/41600 [==============================] - 40s 967us/step - loss: 9.6863e-05 - accuracy: 1.0000 - val_loss: 8.5859e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "41600/41600 [==============================] - 40s 959us/step - loss: 6.1402e-05 - accuracy: 1.0000 - val_loss: 5.6507e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "41600/41600 [==============================] - 39s 948us/step - loss: 4.1742e-05 - accuracy: 1.0000 - val_loss: 3.9453e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "41600/41600 [==============================] - 40s 952us/step - loss: 2.9808e-05 - accuracy: 1.0000 - val_loss: 2.8598e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "41600/41600 [==============================] - 40s 962us/step - loss: 2.1911e-05 - accuracy: 1.0000 - val_loss: 2.1622e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "41600/41600 [==============================] - 39s 945us/step - loss: 1.6901e-05 - accuracy: 1.0000 - val_loss: 1.6128e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "41600/41600 [==============================] - 40s 954us/step - loss: 1.2901e-05 - accuracy: 1.0000 - val_loss: 1.2984e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "41600/41600 [==============================] - 40s 961us/step - loss: 1.0113e-05 - accuracy: 1.0000 - val_loss: 9.7873e-06 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "10400/10400 [==============================] - 7s 703us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   52번 구간 완료\n",
      "\n",
      "\n",
      "   53번 구간 시작\n",
      "\n",
      "Train on 42400 samples, validate on 10600 samples\n",
      "Epoch 1/200\n",
      "42400/42400 [==============================] - 41s 963us/step - loss: 0.2017 - accuracy: 0.9185 - val_loss: 0.0157 - val_accuracy: 0.9978\n",
      "Epoch 2/200\n",
      "42400/42400 [==============================] - 41s 963us/step - loss: 0.0176 - accuracy: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9999\n",
      "Epoch 3/200\n",
      "42400/42400 [==============================] - 41s 960us/step - loss: 7.9073e-04 - accuracy: 1.0000 - val_loss: 2.7754e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "42400/42400 [==============================] - 40s 953us/step - loss: 1.9328e-04 - accuracy: 1.0000 - val_loss: 1.2612e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "42400/42400 [==============================] - 41s 962us/step - loss: 9.8397e-05 - accuracy: 1.0000 - val_loss: 7.2597e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "42400/42400 [==============================] - 41s 959us/step - loss: 6.0073e-05 - accuracy: 1.0000 - val_loss: 4.7443e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "42400/42400 [==============================] - 41s 963us/step - loss: 4.0631e-05 - accuracy: 1.0000 - val_loss: 3.3437e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42400/42400 [==============================] - 40s 940us/step - loss: 2.9316e-05 - accuracy: 1.0000 - val_loss: 2.4752e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "42400/42400 [==============================] - 40s 953us/step - loss: 2.2072e-05 - accuracy: 1.0000 - val_loss: 1.8934e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "42400/42400 [==============================] - 41s 962us/step - loss: 1.7092e-05 - accuracy: 1.0000 - val_loss: 1.4828e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "42400/42400 [==============================] - 41s 961us/step - loss: 1.3485e-05 - accuracy: 1.0000 - val_loss: 1.1785e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "42400/42400 [==============================] - 41s 960us/step - loss: 1.0787e-05 - accuracy: 1.0000 - val_loss: 9.4779e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "42400/42400 [==============================] - 40s 942us/step - loss: 8.7191e-06 - accuracy: 1.0000 - val_loss: 7.6830e-06 - val_accuracy: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "10600/10600 [==============================] - 8s 709us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   53번 구간 완료\n",
      "\n",
      "\n",
      "   54번 구간 시작\n",
      "\n",
      "Train on 43200 samples, validate on 10800 samples\n",
      "Epoch 1/200\n",
      "43200/43200 [==============================] - 41s 959us/step - loss: 0.1988 - accuracy: 0.9134 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 2/200\n",
      "43200/43200 [==============================] - 41s 953us/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 3.7917e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "43200/43200 [==============================] - 42s 967us/step - loss: 2.3714e-04 - accuracy: 1.0000 - val_loss: 1.5366e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "43200/43200 [==============================] - 41s 945us/step - loss: 1.1119e-04 - accuracy: 1.0000 - val_loss: 8.5503e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "43200/43200 [==============================] - 41s 954us/step - loss: 6.4535e-05 - accuracy: 1.0000 - val_loss: 5.1407e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "43200/43200 [==============================] - 41s 955us/step - loss: 4.2055e-05 - accuracy: 1.0000 - val_loss: 3.5855e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "43200/43200 [==============================] - 42s 962us/step - loss: 2.8997e-05 - accuracy: 1.0000 - val_loss: 2.5163e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "43200/43200 [==============================] - 42s 963us/step - loss: 2.0980e-05 - accuracy: 1.0000 - val_loss: 1.8496e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "43200/43200 [==============================] - 41s 954us/step - loss: 1.5517e-05 - accuracy: 1.0000 - val_loss: 1.4292e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "43200/43200 [==============================] - 42s 961us/step - loss: 1.1879e-05 - accuracy: 1.0000 - val_loss: 1.1113e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "10800/10800 [==============================] - 8s 707us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   54번 구간 완료\n",
      "\n",
      "\n",
      "   55번 구간 시작\n",
      "\n",
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/200\n",
      "44000/44000 [==============================] - 42s 962us/step - loss: 0.1918 - accuracy: 0.9201 - val_loss: 0.0186 - val_accuracy: 0.9972\n",
      "Epoch 2/200\n",
      "44000/44000 [==============================] - 42s 964us/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 4.1373e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "44000/44000 [==============================] - 43s 966us/step - loss: 2.7642e-04 - accuracy: 1.0000 - val_loss: 1.7522e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "44000/44000 [==============================] - 42s 964us/step - loss: 1.3528e-04 - accuracy: 1.0000 - val_loss: 9.8040e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "44000/44000 [==============================] - 43s 969us/step - loss: 8.0716e-05 - accuracy: 1.0000 - val_loss: 6.2543e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "44000/44000 [==============================] - 42s 963us/step - loss: 5.3343e-05 - accuracy: 1.0000 - val_loss: 4.2633e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "44000/44000 [==============================] - 43s 967us/step - loss: 3.7399e-05 - accuracy: 1.0000 - val_loss: 3.0634e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "44000/44000 [==============================] - 42s 957us/step - loss: 2.7256e-05 - accuracy: 1.0000 - val_loss: 2.2721e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "44000/44000 [==============================] - 42s 958us/step - loss: 2.0478e-05 - accuracy: 1.0000 - val_loss: 1.7289e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "44000/44000 [==============================] - 42s 948us/step - loss: 1.5693e-05 - accuracy: 1.0000 - val_loss: 1.3361e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "11000/11000 [==============================] - 8s 706us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   55번 구간 완료\n",
      "\n",
      "\n",
      "   56번 구간 시작\n",
      "\n",
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/200\n",
      "44800/44800 [==============================] - 43s 962us/step - loss: 0.1711 - accuracy: 0.9380 - val_loss: 0.0176 - val_accuracy: 0.9970\n",
      "Epoch 2/200\n",
      "44800/44800 [==============================] - 43s 960us/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 5.3436e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "44800/44800 [==============================] - 43s 962us/step - loss: 3.2875e-04 - accuracy: 1.0000 - val_loss: 1.8807e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "44800/44800 [==============================] - 43s 960us/step - loss: 1.4209e-04 - accuracy: 1.0000 - val_loss: 1.0378e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "44800/44800 [==============================] - 43s 969us/step - loss: 8.2109e-05 - accuracy: 1.0000 - val_loss: 6.4011e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "44800/44800 [==============================] - 43s 964us/step - loss: 5.3240e-05 - accuracy: 1.0000 - val_loss: 4.3737e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "44800/44800 [==============================] - 43s 964us/step - loss: 3.6956e-05 - accuracy: 1.0000 - val_loss: 3.1516e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "44800/44800 [==============================] - 43s 964us/step - loss: 2.6695e-05 - accuracy: 1.0000 - val_loss: 2.3390e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "44800/44800 [==============================] - 43s 961us/step - loss: 1.9960e-05 - accuracy: 1.0000 - val_loss: 1.7764e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "44800/44800 [==============================] - 43s 961us/step - loss: 1.5180e-05 - accuracy: 1.0000 - val_loss: 1.3697e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "11200/11200 [==============================] - 8s 704us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   56번 구간 완료\n",
      "\n",
      "\n",
      "   57번 구간 시작\n",
      "\n",
      "Train on 45600 samples, validate on 11400 samples\n",
      "Epoch 1/200\n",
      "45600/45600 [==============================] - 44s 972us/step - loss: 0.1577 - accuracy: 0.9374 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 2/200\n",
      "45600/45600 [==============================] - 44s 965us/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 3.9788e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "45600/45600 [==============================] - 44s 964us/step - loss: 2.6948e-04 - accuracy: 1.0000 - val_loss: 1.6556e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "45600/45600 [==============================] - 43s 945us/step - loss: 1.3143e-04 - accuracy: 1.0000 - val_loss: 9.2700e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "45600/45600 [==============================] - 43s 953us/step - loss: 7.8283e-05 - accuracy: 1.0000 - val_loss: 5.9631e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "45600/45600 [==============================] - 44s 961us/step - loss: 5.1722e-05 - accuracy: 1.0000 - val_loss: 4.0350e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "45600/45600 [==============================] - 44s 963us/step - loss: 3.6101e-05 - accuracy: 1.0000 - val_loss: 2.8899e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "45600/45600 [==============================] - 44s 961us/step - loss: 2.6136e-05 - accuracy: 1.0000 - val_loss: 2.1548e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "45600/45600 [==============================] - 44s 971us/step - loss: 1.9575e-05 - accuracy: 1.0000 - val_loss: 1.6228e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "45600/45600 [==============================] - 44s 967us/step - loss: 1.4864e-05 - accuracy: 1.0000 - val_loss: 1.2546e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "11400/11400 [==============================] - 8s 704us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   57번 구간 완료\n",
      "\n",
      "\n",
      "   58번 구간 시작\n",
      "\n",
      "Train on 46400 samples, validate on 11600 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46400/46400 [==============================] - 45s 967us/step - loss: 0.1667 - accuracy: 0.9350 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
      "Epoch 2/200\n",
      "46400/46400 [==============================] - 45s 960us/step - loss: 7.4900e-04 - accuracy: 0.9999 - val_loss: 2.4006e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "46400/46400 [==============================] - 44s 941us/step - loss: 0.0256 - accuracy: 0.9957 - val_loss: 0.0187 - val_accuracy: 0.9967\n",
      "Epoch 4/200\n",
      "46400/46400 [==============================] - 44s 945us/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
      "Epoch 5/200\n",
      "46400/46400 [==============================] - 44s 952us/step - loss: 5.9736e-04 - accuracy: 1.0000 - val_loss: 2.7427e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "46400/46400 [==============================] - 45s 961us/step - loss: 1.9676e-04 - accuracy: 1.0000 - val_loss: 1.4754e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "46400/46400 [==============================] - 44s 947us/step - loss: 1.1810e-04 - accuracy: 1.0000 - val_loss: 9.4991e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "46400/46400 [==============================] - 44s 943us/step - loss: 7.9547e-05 - accuracy: 1.0000 - val_loss: 6.6289e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "46400/46400 [==============================] - 44s 947us/step - loss: 5.6929e-05 - accuracy: 1.0000 - val_loss: 4.8384e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "46400/46400 [==============================] - 45s 962us/step - loss: 4.2315e-05 - accuracy: 1.0000 - val_loss: 3.6471e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "46400/46400 [==============================] - 44s 958us/step - loss: 3.2230e-05 - accuracy: 1.0000 - val_loss: 2.8046e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "46400/46400 [==============================] - 44s 957us/step - loss: 2.4988e-05 - accuracy: 1.0000 - val_loss: 2.1905e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "11600/11600 [==============================] - 8s 709us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   58번 구간 완료\n",
      "\n",
      "\n",
      "   59번 구간 시작\n",
      "\n",
      "Train on 47200 samples, validate on 11800 samples\n",
      "Epoch 1/200\n",
      "47200/47200 [==============================] - 46s 974us/step - loss: 0.1577 - accuracy: 0.9379 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 2/200\n",
      "47200/47200 [==============================] - 46s 971us/step - loss: 5.1531e-04 - accuracy: 1.0000 - val_loss: 2.4675e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "47200/47200 [==============================] - 46s 969us/step - loss: 1.5292e-04 - accuracy: 1.0000 - val_loss: 1.1220e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "47200/47200 [==============================] - 46s 969us/step - loss: 0.1334 - accuracy: 0.9522 - val_loss: 0.0129 - val_accuracy: 0.9963\n",
      "Epoch 5/200\n",
      "47200/47200 [==============================] - 46s 973us/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 8.9498e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "47200/47200 [==============================] - 45s 959us/step - loss: 5.0865e-04 - accuracy: 1.0000 - val_loss: 3.7368e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "47200/47200 [==============================] - 46s 966us/step - loss: 2.5883e-04 - accuracy: 1.0000 - val_loss: 2.1536e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "47200/47200 [==============================] - 45s 963us/step - loss: 1.6068e-04 - accuracy: 1.0000 - val_loss: 1.4057e-04 - val_accuracy: 1.0000\n",
      "Epoch 00008: early stopping\n",
      "11800/11800 [==============================] - 8s 703us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   59번 구간 완료\n",
      "\n",
      "\n",
      "   60번 구간 시작\n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 46s 957us/step - loss: 0.1690 - accuracy: 0.9341 - val_loss: 0.0140 - val_accuracy: 0.9971\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 46s 969us/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 4.2837e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 46s 962us/step - loss: 2.7554e-04 - accuracy: 1.0000 - val_loss: 1.8646e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 46s 957us/step - loss: 1.3577e-04 - accuracy: 1.0000 - val_loss: 1.0269e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 45s 947us/step - loss: 8.0386e-05 - accuracy: 1.0000 - val_loss: 6.4549e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 46s 963us/step - loss: 5.1468e-05 - accuracy: 1.0000 - val_loss: 4.2748e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 46s 954us/step - loss: 3.5084e-05 - accuracy: 1.0000 - val_loss: 2.9953e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 47s 969us/step - loss: 2.4977e-05 - accuracy: 1.0000 - val_loss: 2.1630e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 46s 961us/step - loss: 1.8192e-05 - accuracy: 1.0000 - val_loss: 1.5876e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 46s 965us/step - loss: 1.3729e-05 - accuracy: 1.0000 - val_loss: 1.2097e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "12000/12000 [==============================] - 8s 708us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   60번 구간 완료\n",
      "\n",
      "\n",
      "   61번 구간 시작\n",
      "\n",
      "Train on 48800 samples, validate on 12200 samples\n",
      "Epoch 1/200\n",
      "48800/48800 [==============================] - 47s 969us/step - loss: 0.1739 - accuracy: 0.9331 - val_loss: 0.0228 - val_accuracy: 0.9965\n",
      "Epoch 2/200\n",
      "48800/48800 [==============================] - 47s 966us/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 7.5377e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "48800/48800 [==============================] - 47s 967us/step - loss: 3.6994e-04 - accuracy: 1.0000 - val_loss: 2.7648e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "48800/48800 [==============================] - 47s 966us/step - loss: 1.6110e-04 - accuracy: 1.0000 - val_loss: 1.4497e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "48800/48800 [==============================] - 47s 967us/step - loss: 9.0143e-05 - accuracy: 1.0000 - val_loss: 8.8651e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "48800/48800 [==============================] - 47s 966us/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9964\n",
      "Epoch 7/200\n",
      "48800/48800 [==============================] - 47s 966us/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 7.1799e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "48800/48800 [==============================] - 47s 967us/step - loss: 2.9330e-04 - accuracy: 1.0000 - val_loss: 1.8570e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "48800/48800 [==============================] - 47s 961us/step - loss: 1.0881e-04 - accuracy: 1.0000 - val_loss: 9.0937e-05 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "12200/12200 [==============================] - 9s 711us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   61번 구간 완료\n",
      "\n",
      "\n",
      "   62번 구간 시작\n",
      "\n",
      "Train on 49600 samples, validate on 12400 samples\n",
      "Epoch 1/200\n",
      "49600/49600 [==============================] - 48s 973us/step - loss: 0.1529 - accuracy: 0.9420 - val_loss: 0.0199 - val_accuracy: 0.9967\n",
      "Epoch 2/200\n",
      "49600/49600 [==============================] - 48s 964us/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 4.3313e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "49600/49600 [==============================] - 48s 973us/step - loss: 2.7347e-04 - accuracy: 1.0000 - val_loss: 1.8786e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "49600/49600 [==============================] - 48s 965us/step - loss: 1.3533e-04 - accuracy: 1.0000 - val_loss: 1.0736e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "49600/49600 [==============================] - 48s 967us/step - loss: 8.0513e-05 - accuracy: 1.0000 - val_loss: 6.7170e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "49600/49600 [==============================] - 48s 964us/step - loss: 5.2639e-05 - accuracy: 1.0000 - val_loss: 4.5990e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "49600/49600 [==============================] - 48s 966us/step - loss: 3.6356e-05 - accuracy: 1.0000 - val_loss: 3.3180e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "49600/49600 [==============================] - 48s 971us/step - loss: 2.6130e-05 - accuracy: 1.0000 - val_loss: 2.4082e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49600/49600 [==============================] - 48s 968us/step - loss: 1.9298e-05 - accuracy: 1.0000 - val_loss: 1.8100e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "49600/49600 [==============================] - 48s 969us/step - loss: 1.4533e-05 - accuracy: 1.0000 - val_loss: 1.4043e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "12400/12400 [==============================] - 9s 699us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   62번 구간 완료\n",
      "\n",
      "\n",
      "   63번 구간 시작\n",
      "\n",
      "Train on 50400 samples, validate on 12600 samples\n",
      "Epoch 1/200\n",
      "50400/50400 [==============================] - 49s 972us/step - loss: 0.1703 - accuracy: 0.9325 - val_loss: 0.0198 - val_accuracy: 0.9968\n",
      "Epoch 2/200\n",
      "50400/50400 [==============================] - 49s 963us/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 4.8426e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "50400/50400 [==============================] - 49s 966us/step - loss: 2.6408e-04 - accuracy: 1.0000 - val_loss: 1.6786e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "50400/50400 [==============================] - 49s 967us/step - loss: 1.2047e-04 - accuracy: 1.0000 - val_loss: 9.0787e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "50400/50400 [==============================] - 49s 970us/step - loss: 6.9976e-05 - accuracy: 1.0000 - val_loss: 5.6284e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "50400/50400 [==============================] - 49s 967us/step - loss: 4.4904e-05 - accuracy: 1.0000 - val_loss: 3.6860e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "50400/50400 [==============================] - 49s 970us/step - loss: 3.0487e-05 - accuracy: 1.0000 - val_loss: 2.5629e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "50400/50400 [==============================] - 49s 967us/step - loss: 2.1520e-05 - accuracy: 1.0000 - val_loss: 1.8256e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "50400/50400 [==============================] - 49s 970us/step - loss: 1.5692e-05 - accuracy: 1.0000 - val_loss: 1.3483e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "50400/50400 [==============================] - 49s 966us/step - loss: 1.1649e-05 - accuracy: 1.0000 - val_loss: 1.0069e-05 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "12600/12600 [==============================] - 9s 713us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   63번 구간 완료\n",
      "\n",
      "\n",
      "   64번 구간 시작\n",
      "\n",
      "Train on 51200 samples, validate on 12800 samples\n",
      "Epoch 1/200\n",
      "51200/51200 [==============================] - 49s 962us/step - loss: 0.1487 - accuracy: 0.9446 - val_loss: 0.0050 - val_accuracy: 0.9979\n",
      "Epoch 2/200\n",
      "51200/51200 [==============================] - 50s 968us/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 9.6592e-04 - val_accuracy: 0.9999\n",
      "Epoch 3/200\n",
      "51200/51200 [==============================] - 50s 972us/step - loss: 0.0521 - accuracy: 0.9899 - val_loss: 0.0078 - val_accuracy: 0.9978\n",
      "Epoch 4/200\n",
      "51200/51200 [==============================] - 50s 970us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 3.7634e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "51200/51200 [==============================] - 49s 963us/step - loss: 2.7575e-04 - accuracy: 1.0000 - val_loss: 1.9529e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "51200/51200 [==============================] - 50s 969us/step - loss: 1.5790e-04 - accuracy: 1.0000 - val_loss: 1.2257e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "51200/51200 [==============================] - 50s 971us/step - loss: 1.0352e-04 - accuracy: 1.0000 - val_loss: 8.3924e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "51200/51200 [==============================] - 50s 977us/step - loss: 7.2875e-05 - accuracy: 1.0000 - val_loss: 6.0618e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "51200/51200 [==============================] - 50s 973us/step - loss: 5.3535e-05 - accuracy: 1.0000 - val_loss: 4.5252e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "51200/51200 [==============================] - 50s 976us/step - loss: 4.0379e-05 - accuracy: 1.0000 - val_loss: 3.4451e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "51200/51200 [==============================] - 49s 966us/step - loss: 3.0997e-05 - accuracy: 1.0000 - val_loss: 2.6628e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "51200/51200 [==============================] - 49s 960us/step - loss: 2.4092e-05 - accuracy: 1.0000 - val_loss: 2.0791e-05 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "12800/12800 [==============================] - 9s 703us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   64번 구간 완료\n",
      "\n",
      "\n",
      "   65번 구간 시작\n",
      "\n",
      "Train on 52000 samples, validate on 13000 samples\n",
      "Epoch 1/200\n",
      "52000/52000 [==============================] - 51s 978us/step - loss: 0.1729 - accuracy: 0.9341 - val_loss: 0.0224 - val_accuracy: 0.9968\n",
      "Epoch 2/200\n",
      "52000/52000 [==============================] - 51s 973us/step - loss: 0.0187 - accuracy: 0.9970 - val_loss: 0.0175 - val_accuracy: 0.9968\n",
      "Epoch 3/200\n",
      "52000/52000 [==============================] - 51s 978us/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 4.0055e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "52000/52000 [==============================] - 51s 978us/step - loss: 2.3375e-04 - accuracy: 1.0000 - val_loss: 1.5077e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "52000/52000 [==============================] - 51s 975us/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0153 - val_accuracy: 0.9968\n",
      "Epoch 6/200\n",
      "52000/52000 [==============================] - 51s 980us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.9165e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "52000/52000 [==============================] - 51s 973us/step - loss: 1.8539e-04 - accuracy: 1.0000 - val_loss: 1.2774e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "52000/52000 [==============================] - 50s 966us/step - loss: 9.7213e-05 - accuracy: 1.0000 - val_loss: 7.7157e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "52000/52000 [==============================] - 50s 953us/step - loss: 6.2263e-05 - accuracy: 1.0000 - val_loss: 5.1992e-05 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "13000/13000 [==============================] - 9s 714us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   65번 구간 완료\n",
      "\n",
      "\n",
      "   66번 구간 시작\n",
      "\n",
      "Train on 52800 samples, validate on 13200 samples\n",
      "Epoch 1/200\n",
      "52800/52800 [==============================] - 52s 976us/step - loss: 0.1407 - accuracy: 0.9416 - val_loss: 9.5143e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "52800/52800 [==============================] - 52s 976us/step - loss: 3.7368e-04 - accuracy: 1.0000 - val_loss: 1.7300e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "52800/52800 [==============================] - 52s 976us/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 2.7033e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "52800/52800 [==============================] - 52s 977us/step - loss: 1.5979e-04 - accuracy: 1.0000 - val_loss: 9.6580e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "52800/52800 [==============================] - 52s 977us/step - loss: 7.2416e-05 - accuracy: 1.0000 - val_loss: 5.2161e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "52800/52800 [==============================] - 51s 975us/step - loss: 4.2609e-05 - accuracy: 1.0000 - val_loss: 3.2942e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "52800/52800 [==============================] - 51s 972us/step - loss: 2.7905e-05 - accuracy: 1.0000 - val_loss: 2.2378e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "52800/52800 [==============================] - 52s 977us/step - loss: 1.9437e-05 - accuracy: 1.0000 - val_loss: 1.5921e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "52800/52800 [==============================] - 51s 975us/step - loss: 1.4090e-05 - accuracy: 1.0000 - val_loss: 1.1709e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "52800/52800 [==============================] - 52s 976us/step - loss: 1.0487e-05 - accuracy: 1.0000 - val_loss: 8.8021e-06 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "13200/13200 [==============================] - 10s 724us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   66번 구간 완료\n",
      "\n",
      "\n",
      "   67번 구간 시작\n",
      "\n",
      "Train on 53600 samples, validate on 13400 samples\n",
      "Epoch 1/200\n",
      "53600/53600 [==============================] - 52s 977us/step - loss: 0.1420 - accuracy: 0.9481 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 2/200\n",
      "53600/53600 [==============================] - 53s 980us/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 3/200\n",
      "53600/53600 [==============================] - 53s 986us/step - loss: 9.2343e-04 - accuracy: 1.0000 - val_loss: 3.4827e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53600/53600 [==============================] - 52s 979us/step - loss: 5.5134e-04 - accuracy: 1.0000 - val_loss: 1.7524e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "53600/53600 [==============================] - 53s 981us/step - loss: 7.9317e-04 - accuracy: 1.0000 - val_loss: 1.9896e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "53600/53600 [==============================] - 53s 982us/step - loss: 1.3168e-04 - accuracy: 1.0000 - val_loss: 8.8583e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "53600/53600 [==============================] - 52s 978us/step - loss: 6.7995e-05 - accuracy: 1.0000 - val_loss: 5.2252e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "53600/53600 [==============================] - 52s 974us/step - loss: 4.2370e-05 - accuracy: 1.0000 - val_loss: 3.4405e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "53600/53600 [==============================] - 52s 978us/step - loss: 2.8668e-05 - accuracy: 1.0000 - val_loss: 2.4006e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "53600/53600 [==============================] - 53s 980us/step - loss: 2.0324e-05 - accuracy: 1.0000 - val_loss: 1.7342e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "53600/53600 [==============================] - 52s 979us/step - loss: 1.4847e-05 - accuracy: 1.0000 - val_loss: 1.2838e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "53600/53600 [==============================] - 52s 976us/step - loss: 1.1073e-05 - accuracy: 1.0000 - val_loss: 9.6575e-06 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "13400/13400 [==============================] - 9s 706us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   67번 구간 완료\n",
      "\n",
      "\n",
      "   68번 구간 시작\n",
      "\n",
      "Train on 54400 samples, validate on 13600 samples\n",
      "Epoch 1/200\n",
      "54400/54400 [==============================] - 53s 972us/step - loss: 0.1377 - accuracy: 0.9463 - val_loss: 9.7833e-04 - val_accuracy: 0.9999\n",
      "Epoch 2/200\n",
      "54400/54400 [==============================] - 53s 976us/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 2.9240e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "54400/54400 [==============================] - 53s 970us/step - loss: 1.6505e-04 - accuracy: 1.0000 - val_loss: 1.1025e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "54400/54400 [==============================] - 53s 970us/step - loss: 7.5956e-05 - accuracy: 1.0000 - val_loss: 5.9069e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "54400/54400 [==============================] - 53s 967us/step - loss: 4.3669e-05 - accuracy: 1.0000 - val_loss: 3.6096e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "54400/54400 [==============================] - 53s 969us/step - loss: 2.7885e-05 - accuracy: 1.0000 - val_loss: 2.3872e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "54400/54400 [==============================] - 53s 976us/step - loss: 1.8863e-05 - accuracy: 1.0000 - val_loss: 1.6506e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "54400/54400 [==============================] - 53s 978us/step - loss: 1.3278e-05 - accuracy: 1.0000 - val_loss: 1.1850e-05 - val_accuracy: 1.0000\n",
      "Epoch 00008: early stopping\n",
      "13600/13600 [==============================] - 10s 712us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   68번 구간 완료\n",
      "\n",
      "\n",
      "   69번 구간 시작\n",
      "\n",
      "Train on 55200 samples, validate on 13800 samples\n",
      "Epoch 1/200\n",
      "55200/55200 [==============================] - 54s 983us/step - loss: 0.1374 - accuracy: 0.9481 - val_loss: 0.0121 - val_accuracy: 0.9972\n",
      "Epoch 2/200\n",
      "55200/55200 [==============================] - 54s 981us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 3.5627e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "55200/55200 [==============================] - 54s 980us/step - loss: 2.3211e-04 - accuracy: 1.0000 - val_loss: 1.3536e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "55200/55200 [==============================] - 54s 979us/step - loss: 1.0427e-04 - accuracy: 1.0000 - val_loss: 7.1438e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "55200/55200 [==============================] - 54s 974us/step - loss: 5.8436e-05 - accuracy: 1.0000 - val_loss: 4.2763e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "55200/55200 [==============================] - 54s 977us/step - loss: 3.6501e-05 - accuracy: 1.0000 - val_loss: 2.7882e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "55200/55200 [==============================] - 54s 977us/step - loss: 2.4341e-05 - accuracy: 1.0000 - val_loss: 1.9086e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "55200/55200 [==============================] - 54s 980us/step - loss: 1.6841e-05 - accuracy: 1.0000 - val_loss: 1.3548e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "55200/55200 [==============================] - 54s 981us/step - loss: 1.2043e-05 - accuracy: 1.0000 - val_loss: 9.8581e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "55200/55200 [==============================] - 54s 971us/step - loss: 8.7812e-06 - accuracy: 1.0000 - val_loss: 7.2924e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "55200/55200 [==============================] - 54s 983us/step - loss: 6.5399e-06 - accuracy: 1.0000 - val_loss: 5.4679e-06 - val_accuracy: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "13800/13800 [==============================] - 10s 700us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   69번 구간 완료\n",
      "\n",
      "\n",
      "   70번 구간 시작\n",
      "\n",
      "Train on 56000 samples, validate on 14000 samples\n",
      "Epoch 1/200\n",
      "56000/56000 [==============================] - 55s 982us/step - loss: 0.1332 - accuracy: 0.9431 - val_loss: 6.6376e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "56000/56000 [==============================] - 55s 980us/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.0338 - val_accuracy: 0.9960\n",
      "Epoch 3/200\n",
      "56000/56000 [==============================] - 54s 963us/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 4.3704e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "56000/56000 [==============================] - 54s 962us/step - loss: 2.2840e-04 - accuracy: 1.0000 - val_loss: 1.4215e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "56000/56000 [==============================] - 54s 971us/step - loss: 1.0096e-04 - accuracy: 1.0000 - val_loss: 7.6847e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "56000/56000 [==============================] - 55s 975us/step - loss: 6.0109e-05 - accuracy: 1.0000 - val_loss: 4.8675e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "56000/56000 [==============================] - 55s 981us/step - loss: 3.9422e-05 - accuracy: 1.0000 - val_loss: 3.2847e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "56000/56000 [==============================] - 55s 975us/step - loss: 2.7308e-05 - accuracy: 1.0000 - val_loss: 2.3206e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "56000/56000 [==============================] - 54s 969us/step - loss: 1.9590e-05 - accuracy: 1.0000 - val_loss: 1.6826e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "56000/56000 [==============================] - 55s 980us/step - loss: 1.4383e-05 - accuracy: 1.0000 - val_loss: 1.2529e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "56000/56000 [==============================] - 55s 981us/step - loss: 1.0751e-05 - accuracy: 1.0000 - val_loss: 9.3890e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "56000/56000 [==============================] - 55s 984us/step - loss: 8.1524e-06 - accuracy: 1.0000 - val_loss: 7.1635e-06 - val_accuracy: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "14000/14000 [==============================] - 10s 713us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   70번 구간 완료\n",
      "\n",
      "\n",
      "   71번 구간 시작\n",
      "\n",
      "Train on 56800 samples, validate on 14200 samples\n",
      "Epoch 1/200\n",
      "56800/56800 [==============================] - 56s 980us/step - loss: 0.1409 - accuracy: 0.9440 - val_loss: 0.0202 - val_accuracy: 0.9964\n",
      "Epoch 2/200\n",
      "56800/56800 [==============================] - 55s 965us/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 3.5261e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "56800/56800 [==============================] - 56s 983us/step - loss: 2.2364e-04 - accuracy: 1.0000 - val_loss: 1.4681e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "56800/56800 [==============================] - 56s 983us/step - loss: 1.0819e-04 - accuracy: 1.0000 - val_loss: 8.1207e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "56800/56800 [==============================] - 56s 980us/step - loss: 6.3613e-05 - accuracy: 1.0000 - val_loss: 5.0691e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "56800/56800 [==============================] - 56s 978us/step - loss: 4.1194e-05 - accuracy: 1.0000 - val_loss: 3.4060e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "56800/56800 [==============================] - 56s 981us/step - loss: 2.8261e-05 - accuracy: 1.0000 - val_loss: 2.3932e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56800/56800 [==============================] - 55s 972us/step - loss: 2.0141e-05 - accuracy: 1.0000 - val_loss: 1.7364e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "56800/56800 [==============================] - 56s 978us/step - loss: 1.4742e-05 - accuracy: 1.0000 - val_loss: 1.2846e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "56800/56800 [==============================] - 55s 975us/step - loss: 1.1005e-05 - accuracy: 1.0000 - val_loss: 9.6737e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "56800/56800 [==============================] - 56s 983us/step - loss: 8.3222e-06 - accuracy: 1.0000 - val_loss: 7.3631e-06 - val_accuracy: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "14200/14200 [==============================] - 10s 713us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   71번 구간 완료\n",
      "\n",
      "\n",
      "   72번 구간 시작\n",
      "\n",
      "Train on 57600 samples, validate on 14400 samples\n",
      "Epoch 1/200\n",
      "57600/57600 [==============================] - 57s 983us/step - loss: 0.1380 - accuracy: 0.9410 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 2/200\n",
      "57600/57600 [==============================] - 56s 972us/step - loss: 0.1922 - accuracy: 0.9035 - val_loss: 0.2250 - val_accuracy: 0.8627\n",
      "Epoch 3/200\n",
      "57600/57600 [==============================] - 56s 974us/step - loss: 0.2085 - accuracy: 0.8746 - val_loss: 0.0674 - val_accuracy: 0.9876\n",
      "Epoch 4/200\n",
      "57600/57600 [==============================] - 56s 976us/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
      "Epoch 5/200\n",
      "57600/57600 [==============================] - 56s 970us/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 5.8543e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "57600/57600 [==============================] - 56s 974us/step - loss: 4.3865e-04 - accuracy: 1.0000 - val_loss: 3.3955e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "57600/57600 [==============================] - 56s 977us/step - loss: 2.6192e-04 - accuracy: 1.0000 - val_loss: 2.0753e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "57600/57600 [==============================] - 54s 943us/step - loss: 1.7126e-04 - accuracy: 1.0000 - val_loss: 1.4436e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "57600/57600 [==============================] - 55s 954us/step - loss: 1.1948e-04 - accuracy: 1.0000 - val_loss: 9.8572e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "57600/57600 [==============================] - 56s 978us/step - loss: 8.2444e-05 - accuracy: 1.0000 - val_loss: 7.1071e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "57600/57600 [==============================] - 56s 976us/step - loss: 6.0122e-05 - accuracy: 1.0000 - val_loss: 5.1333e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "57600/57600 [==============================] - 56s 974us/step - loss: 4.4193e-05 - accuracy: 1.0000 - val_loss: 3.8167e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "57600/57600 [==============================] - 56s 980us/step - loss: 3.2662e-05 - accuracy: 1.0000 - val_loss: 2.8885e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "57600/57600 [==============================] - 56s 974us/step - loss: 2.4729e-05 - accuracy: 1.0000 - val_loss: 2.2143e-05 - val_accuracy: 1.0000\n",
      "Epoch 00014: early stopping\n",
      "14400/14400 [==============================] - 10s 714us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   72번 구간 완료\n",
      "\n",
      "\n",
      "   73번 구간 시작\n",
      "\n",
      "Train on 58400 samples, validate on 14600 samples\n",
      "Epoch 1/200\n",
      "58400/58400 [==============================] - 57s 981us/step - loss: 0.1313 - accuracy: 0.9504 - val_loss: 9.5345e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "58400/58400 [==============================] - 57s 974us/step - loss: 3.8097e-04 - accuracy: 1.0000 - val_loss: 1.6104e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "58400/58400 [==============================] - 57s 981us/step - loss: 0.0240 - accuracy: 0.9960 - val_loss: 0.0187 - val_accuracy: 0.9966\n",
      "Epoch 4/200\n",
      "58400/58400 [==============================] - 57s 982us/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 2.2207e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "58400/58400 [==============================] - 57s 977us/step - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 9.8816e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "58400/58400 [==============================] - 57s 981us/step - loss: 7.6503e-05 - accuracy: 1.0000 - val_loss: 5.9242e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "58400/58400 [==============================] - 58s 989us/step - loss: 4.8441e-05 - accuracy: 1.0000 - val_loss: 3.9177e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "58400/58400 [==============================] - 58s 985us/step - loss: 3.3090e-05 - accuracy: 1.0000 - val_loss: 2.7388e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "58400/58400 [==============================] - 57s 981us/step - loss: 2.3581e-05 - accuracy: 1.0000 - val_loss: 1.9737e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "58400/58400 [==============================] - 57s 973us/step - loss: 1.7248e-05 - accuracy: 1.0000 - val_loss: 1.4568e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "58400/58400 [==============================] - 57s 977us/step - loss: 1.2841e-05 - accuracy: 1.0000 - val_loss: 1.0902e-05 - val_accuracy: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "14600/14600 [==============================] - 10s 717us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   73번 구간 완료\n",
      "\n",
      "\n",
      "   74번 구간 시작\n",
      "\n",
      "Train on 59200 samples, validate on 14800 samples\n",
      "Epoch 1/200\n",
      "59200/59200 [==============================] - 58s 983us/step - loss: 0.1177 - accuracy: 0.9549 - val_loss: 5.5589e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "59200/59200 [==============================] - 58s 981us/step - loss: 2.7257e-04 - accuracy: 1.0000 - val_loss: 1.3103e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "59200/59200 [==============================] - 58s 975us/step - loss: 8.9074e-05 - accuracy: 1.0000 - val_loss: 5.7655e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "59200/59200 [==============================] - 58s 983us/step - loss: 4.4579e-05 - accuracy: 1.0000 - val_loss: 3.2228e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "59200/59200 [==============================] - 58s 977us/step - loss: 2.6399e-05 - accuracy: 1.0000 - val_loss: 2.4333e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "59200/59200 [==============================] - 58s 977us/step - loss: 1.6811e-05 - accuracy: 1.0000 - val_loss: 1.3286e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "59200/59200 [==============================] - 57s 971us/step - loss: 1.1571e-05 - accuracy: 1.0000 - val_loss: 9.3035e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "59200/59200 [==============================] - 58s 975us/step - loss: 8.0662e-06 - accuracy: 1.0000 - val_loss: 6.7163e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "59200/59200 [==============================] - 58s 978us/step - loss: 5.8741e-06 - accuracy: 1.0000 - val_loss: 4.8774e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "59200/59200 [==============================] - 58s 977us/step - loss: 4.3445e-06 - accuracy: 1.0000 - val_loss: 3.6510e-06 - val_accuracy: 1.0000\n",
      "Epoch 00010: early stopping\n",
      "14800/14800 [==============================] - 10s 702us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   74번 구간 완료\n",
      "\n",
      "\n",
      "   75번 구간 시작\n",
      "\n",
      "Train on 60000 samples, validate on 15000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 59s 986us/step - loss: 0.1753 - accuracy: 0.9303 - val_loss: 0.0234 - val_accuracy: 0.9964\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 58s 975us/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 7.8830e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 58s 974us/step - loss: 4.5663e-04 - accuracy: 1.0000 - val_loss: 2.8934e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 59s 981us/step - loss: 2.0784e-04 - accuracy: 1.0000 - val_loss: 1.5591e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 58s 968us/step - loss: 1.2044e-04 - accuracy: 1.0000 - val_loss: 9.6368e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 58s 974us/step - loss: 7.7307e-05 - accuracy: 1.0000 - val_loss: 6.3963e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 59s 978us/step - loss: 0.0220 - accuracy: 0.9954 - val_loss: 9.0516e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 59s 980us/step - loss: 4.8416e-04 - accuracy: 1.0000 - val_loss: 2.9786e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 59s 979us/step - loss: 2.1512e-04 - accuracy: 1.0000 - val_loss: 1.6327e-04 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "15000/15000 [==============================] - 11s 711us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   75번 구간 완료\n",
      "\n",
      "\n",
      "   76번 구간 시작\n",
      "\n",
      "Train on 60800 samples, validate on 15200 samples\n",
      "Epoch 1/200\n",
      "60800/60800 [==============================] - 59s 974us/step - loss: 0.1342 - accuracy: 0.9458 - val_loss: 9.0315e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "60800/60800 [==============================] - 59s 974us/step - loss: 4.0854e-04 - accuracy: 1.0000 - val_loss: 1.7978e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "60800/60800 [==============================] - 58s 955us/step - loss: 1.6477e-04 - accuracy: 1.0000 - val_loss: 1.1227e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "60800/60800 [==============================] - 59s 970us/step - loss: 7.0605e-05 - accuracy: 1.0000 - val_loss: 4.5534e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "60800/60800 [==============================] - 59s 962us/step - loss: 3.6590e-05 - accuracy: 1.0000 - val_loss: 2.7407e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "60800/60800 [==============================] - 59s 978us/step - loss: 2.2936e-05 - accuracy: 1.0000 - val_loss: 1.8149e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "60800/60800 [==============================] - 59s 977us/step - loss: 1.5427e-05 - accuracy: 1.0000 - val_loss: 1.2464e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "60800/60800 [==============================] - 59s 978us/step - loss: 1.0835e-05 - accuracy: 1.0000 - val_loss: 8.9188e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "60800/60800 [==============================] - 60s 979us/step - loss: 7.8274e-06 - accuracy: 1.0000 - val_loss: 6.5515e-06 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "15200/15200 [==============================] - 11s 713us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   76번 구간 완료\n",
      "\n",
      "\n",
      "   77번 구간 시작\n",
      "\n",
      "Train on 61600 samples, validate on 15400 samples\n",
      "Epoch 1/200\n",
      "61600/61600 [==============================] - 61s 984us/step - loss: 0.1275 - accuracy: 0.9502 - val_loss: 0.0064 - val_accuracy: 0.9971\n",
      "Epoch 2/200\n",
      "61600/61600 [==============================] - 60s 981us/step - loss: 8.9298e-04 - accuracy: 0.9998 - val_loss: 2.0734e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "61600/61600 [==============================] - 60s 981us/step - loss: 1.2725e-04 - accuracy: 1.0000 - val_loss: 7.9865e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "61600/61600 [==============================] - 60s 974us/step - loss: 5.9197e-05 - accuracy: 1.0000 - val_loss: 4.1816e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "61600/61600 [==============================] - 60s 979us/step - loss: 3.3827e-05 - accuracy: 1.0000 - val_loss: 2.5691e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "61600/61600 [==============================] - 61s 984us/step - loss: 2.1394e-05 - accuracy: 1.0000 - val_loss: 1.6739e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "61600/61600 [==============================] - 61s 985us/step - loss: 1.4360e-05 - accuracy: 1.0000 - val_loss: 1.1473e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "61600/61600 [==============================] - 61s 984us/step - loss: 1.0020e-05 - accuracy: 1.0000 - val_loss: 8.1707e-06 - val_accuracy: 1.0000\n",
      "Epoch 00008: early stopping\n",
      "15400/15400 [==============================] - 11s 716us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   77번 구간 완료\n",
      "\n",
      "\n",
      "   78번 구간 시작\n",
      "\n",
      "Train on 62400 samples, validate on 15600 samples\n",
      "Epoch 1/200\n",
      "62400/62400 [==============================] - 61s 981us/step - loss: 0.1310 - accuracy: 0.9450 - val_loss: 7.3497e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "62400/62400 [==============================] - 61s 972us/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 9.7690e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "62400/62400 [==============================] - 61s 973us/step - loss: 4.2165e-04 - accuracy: 1.0000 - val_loss: 2.2733e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "62400/62400 [==============================] - 61s 976us/step - loss: 1.5447e-04 - accuracy: 1.0000 - val_loss: 1.1148e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "62400/62400 [==============================] - 61s 973us/step - loss: 8.4089e-05 - accuracy: 1.0000 - val_loss: 6.5888e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "62400/62400 [==============================] - 61s 971us/step - loss: 5.2208e-05 - accuracy: 1.0000 - val_loss: 4.2620e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "62400/62400 [==============================] - 61s 971us/step - loss: 3.4771e-05 - accuracy: 1.0000 - val_loss: 2.9096e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "62400/62400 [==============================] - 61s 974us/step - loss: 2.4184e-05 - accuracy: 1.0000 - val_loss: 2.0591e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "62400/62400 [==============================] - 61s 975us/step - loss: 1.7319e-05 - accuracy: 1.0000 - val_loss: 1.4941e-05 - val_accuracy: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "15600/15600 [==============================] - 11s 712us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n",
      "   78번 구간 완료\n",
      "\n",
      "\n",
      "   79번 구간 시작\n",
      "\n",
      "Train on 63200 samples, validate on 15800 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[63200,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node mul_5551 (defined at C:\\Users\\boinit\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_4283879]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6bd1830ee218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecat_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'math_expr_new.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Python_Workspace\\MExC project\\Decat.py\u001b[0m in \u001b[0;36mDecat_start\u001b[1;34m(data_name, interval)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         history = model.fit(X_train_seq, Y_train_ctg, batch_size=128, \n\u001b[1;32m---> 73\u001b[1;33m                         epochs=200,validation_data=(X_test_seq, Y_test_ctg),callbacks=[earlystop,mc])\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Test Accuracy: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_ctg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[63200,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node mul_5551 (defined at C:\\Users\\boinit\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_4283879]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "model1=Decat.Decat_start('math_expr_new.csv',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 줄 수 설정\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# 최대 열 수 설정\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# 표시할 가로의 길이\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>손실최소값</th>\n",
       "      <th>정확도</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>학습데이터량</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>29</td>\n",
       "      <td>0.037399</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>23</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>15</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>36</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>52</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.995714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21000</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22000</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26000</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34000</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36000</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38000</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39000</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47000</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48000</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66000</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69000</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74000</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81000</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89000</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91000</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96000</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98000</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epoch     손실최소값       정확도\n",
       "학습데이터량                           \n",
       "1000       29  0.037399  0.995000\n",
       "2000       23  0.001811  1.000000\n",
       "3000       15  0.020854  0.996667\n",
       "4000       36  0.000178  1.000000\n",
       "5000       31  0.000148  1.000000\n",
       "6000       52  0.000758  0.999167\n",
       "7000        8  0.018927  0.995714\n",
       "8000       18  0.000123  1.000000\n",
       "9000       14  0.000089  1.000000\n",
       "10000      14  0.000166  1.000000\n",
       "11000      17  0.000063  1.000000\n",
       "12000      16  0.000074  1.000000\n",
       "13000      20  0.000052  1.000000\n",
       "14000      13  0.000086  1.000000\n",
       "15000      14  0.000047  1.000000\n",
       "16000      10  0.000062  1.000000\n",
       "17000      14  0.000081  1.000000\n",
       "18000       9  0.000055  1.000000\n",
       "19000      13  0.000042  1.000000\n",
       "20000      10  0.000124  1.000000\n",
       "21000      13  0.000053  1.000000\n",
       "22000      15  0.000035  1.000000\n",
       "23000       9  0.000038  1.000000\n",
       "24000       7  0.000035  1.000000\n",
       "25000      13  0.000048  1.000000\n",
       "26000       7  0.000047  1.000000\n",
       "27000       9  0.000036  1.000000\n",
       "28000       9  0.000069  1.000000\n",
       "29000       8  0.000048  1.000000\n",
       "30000      18  0.000040  1.000000\n",
       "31000       8  0.000040  1.000000\n",
       "32000       9  0.000043  1.000000\n",
       "33000      10  0.000040  1.000000\n",
       "34000       7  0.000039  1.000000\n",
       "35000       8  0.000019  1.000000\n",
       "36000      12  0.000023  1.000000\n",
       "37000       6  0.000023  1.000000\n",
       "38000       4  0.000157  1.000000\n",
       "39000       7  0.000016  1.000000\n",
       "40000       8  0.000022  1.000000\n",
       "41000       5  0.000051  1.000000\n",
       "42000       8  0.000016  1.000000\n",
       "43000       5  0.000019  1.000000\n",
       "44000       8  0.000018  1.000000\n",
       "45000       9  0.000014  1.000000\n",
       "46000       5  0.000050  1.000000\n",
       "47000       7  0.000024  1.000000\n",
       "48000       9  0.000006  1.000000\n",
       "49000       5  0.000015  1.000000\n",
       "50000       8  0.000009  1.000000\n",
       "51000       6  0.000021  1.000000\n",
       "52000       3  0.000123  1.000000\n",
       "53000       8  0.000009  1.000000\n",
       "54000       5  0.000014  1.000000\n",
       "55000       5  0.000032  1.000000\n",
       "56000       5  0.000012  1.000000\n",
       "57000       8  0.000008  1.000000\n",
       "58000       5  0.000011  1.000000\n",
       "59000       8  0.000004  1.000000\n",
       "60000       3  0.000089  1.000000\n",
       "61000       6  0.000015  1.000000\n",
       "62000       5  0.000012  1.000000\n",
       "63000       3  0.000055  1.000000\n",
       "64000       5  0.000006  1.000000\n",
       "65000       3  0.000018  1.000000\n",
       "66000       4  0.000015  1.000000\n",
       "67000       8  0.000010  1.000000\n",
       "68000       3  0.000055  1.000000\n",
       "69000      13  0.000011  1.000000\n",
       "70000       6  0.000012  1.000000\n",
       "71000       3  0.000012  1.000000\n",
       "72000       6  0.000006  1.000000\n",
       "73000       6  0.000009  1.000000\n",
       "74000       4  0.000006  1.000000\n",
       "75000       3  0.000011  1.000000\n",
       "76000       5  0.000011  1.000000\n",
       "77000       3  0.000009  1.000000\n",
       "78000       3  0.000057  1.000000\n",
       "79000       3  0.000011  1.000000\n",
       "80000       3  0.000008  1.000000\n",
       "81000       4  0.000005  1.000000\n",
       "82000       3  0.000012  1.000000\n",
       "83000       6  0.000007  1.000000\n",
       "84000       3  0.000009  1.000000\n",
       "85000       5  0.000017  1.000000\n",
       "86000       3  0.000008  1.000000\n",
       "87000       3  0.000011  1.000000\n",
       "88000       6  0.000003  1.000000\n",
       "89000       7  0.000003  1.000000\n",
       "90000       3  0.000008  1.000000\n",
       "91000       2  0.000024  1.000000\n",
       "92000       5  0.000013  1.000000\n",
       "93000       3  0.000008  1.000000\n",
       "94000       3  0.000041  1.000000\n",
       "95000       3  0.000005  1.000000\n",
       "96000       8  0.000002  1.000000\n",
       "97000       6  0.000005  1.000000\n",
       "98000       6  0.000005  1.000000\n",
       "99000       3  0.000008  1.000000\n",
       "100000      3  0.000008  1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,7)\n",
    "fig, loss_ax = plt.subplots()\n",
    "epoch_ax = loss_ax.twinx()\n",
    "loss_ax.plot(model1['Epoch'], 'g', label='Epoch',marker='o')\n",
    "epoch_ax.plot(model1['손실최소값'], 'b', label='best val_loss',marker='o')\n",
    "loss_ax.set_xlabel('data',fontsize=18)\n",
    "loss_ax.set_ylabel('Epoch',fontsize=18)\n",
    "epoch_ax.set_ylabel('Val_loss',fontsize=18)\n",
    "loss_ax.legend(loc='lower left',fontsize=15)\n",
    "epoch_ax.legend(loc='upper left',fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "정확도 : 100.0%, 테스트 100문항 중 0문항 예측실패\n"
     ]
    }
   ],
   "source": [
    "result = Decat.Test_Model('./models/best_model_96000.h5','./new_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "원본수식    -8\\left(-7x-1-\\frac{8}{5} x+4\\right)\n",
       "예측값                   distributor_expression\n",
       "정답                    distributor_expression\n",
       "일치여부                                       O\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
